{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87c72ace",
   "metadata": {},
   "source": [
    "# GraphSAGE\n",
    "\n",
    "Thanks to cs224w colab 3\n",
    "\n",
    "In Colab 2 we constructed GNN models by using PyTorch Geometric's built in GCN layer, `GCNConv`. In this Colab we will go a step deeper and implement the **GraphSAGE** ([Hamilton et al. (2017)](https://arxiv.org/abs/1706.02216)) layer directly. Then we will run our models on the CORA dataset, which is a standard citation network benchmark dataset.\n",
    "\n",
    "**Note**: Make sure to **sequentially run all the cells in each section** so that the intermediate variables / packages will carry over to the next cell\n",
    "\n",
    "Have fun and good luck on Colab 3 :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499600ec",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7259e422",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu111.html\n",
      "Requirement already satisfied: torch-scatter in c:\\users\\user\\anaconda3\\envs\\gnn\\lib\\site-packages (2.0.9)\n",
      "Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu111.html\n",
      "Requirement already satisfied: torch-sparse in c:\\users\\user\\anaconda3\\envs\\gnn\\lib\\site-packages (0.6.13)\n",
      "Requirement already satisfied: scipy in c:\\users\\user\\anaconda3\\envs\\gnn\\lib\\site-packages (from torch-sparse) (1.7.3)\n",
      "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in c:\\users\\user\\anaconda3\\envs\\gnn\\lib\\site-packages (from scipy->torch-sparse) (1.21.6)\n",
      "Requirement already satisfied: torch-geometric in c:\\users\\user\\anaconda3\\envs\\gnn\\lib\\site-packages (2.0.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\anaconda3\\envs\\gnn\\lib\\site-packages (from torch-geometric) (1.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\envs\\gnn\\lib\\site-packages (from torch-geometric) (2.28.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\anaconda3\\envs\\gnn\\lib\\site-packages (from torch-geometric) (4.64.0)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\user\\anaconda3\\envs\\gnn\\lib\\site-packages (from torch-geometric) (3.0.9)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\envs\\gnn\\lib\\site-packages (from torch-geometric) (1.21.6)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\anaconda3\\envs\\gnn\\lib\\site-packages (from torch-geometric) (1.3.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\user\\anaconda3\\envs\\gnn\\lib\\site-packages (from torch-geometric) (1.7.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\anaconda3\\envs\\gnn\\lib\\site-packages (from torch-geometric) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\anaconda3\\envs\\gnn\\lib\\site-packages (from jinja2->torch-geometric) (2.1.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\user\\anaconda3\\envs\\gnn\\lib\\site-packages (from pandas->torch-geometric) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\user\\anaconda3\\envs\\gnn\\lib\\site-packages (from pandas->torch-geometric) (2.8.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\envs\\gnn\\lib\\site-packages (from requests->torch-geometric) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\user\\anaconda3\\envs\\gnn\\lib\\site-packages (from requests->torch-geometric) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\envs\\gnn\\lib\\site-packages (from requests->torch-geometric) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\anaconda3\\envs\\gnn\\lib\\site-packages (from requests->torch-geometric) (1.26.11)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\anaconda3\\envs\\gnn\\lib\\site-packages (from scikit-learn->torch-geometric) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\user\\anaconda3\\envs\\gnn\\lib\\site-packages (from scikit-learn->torch-geometric) (1.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\envs\\gnn\\lib\\site-packages (from tqdm->torch-geometric) (0.4.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\anaconda3\\envs\\gnn\\lib\\site-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.16.0)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "  !pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.9.0+cu111.html\n",
    "  !pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-1.9.0+cu111.html\n",
    "  !pip install torch-geometric\n",
    "  !pip install -q git+https://github.com/snap-stanford/deepsnap.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c93a328c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.4'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch_geometric\n",
    "torch_geometric.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a273bc8",
   "metadata": {},
   "source": [
    "## CORA data\n",
    "\n",
    "The Cora dataset consists of 2708 scientific publications classified into one of seven classes. The citation network consists of 5429 links. Each publication in the dataset is described by a 0/1-valued word vector indicating the absence/presence of the corresponding word from the dictionary. The dictionary consists of 1433 unique words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ece76e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "  class objectview(object):\n",
    "    def __init__(self, d):\n",
    "        self.__dict__ = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "acdd75f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "  'model_type': 'GraphSage', \n",
    "  'dataset': 'cora',\n",
    "  'num_layers': 2,\n",
    "  'heads': 1,\n",
    "  'batch_size': 32,\n",
    "  'hidden_dim': 32,\n",
    "  'dropout': 0.5,\n",
    "  'epochs': 500,\n",
    "  'opt': 'adam',\n",
    "  'opt_scheduler': 'none',\n",
    "  'opt_restart': 0,\n",
    "  'weight_decay': 5e-3,\n",
    "  'lr': 0.01}\n",
    "\n",
    "args = objectview(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dec20c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c0fcf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Planetoid(root='/tmp/cora', name='Cora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a2bf75e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cora()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f28d0cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ddefe663",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/gnn/lib/python3.7/site-packages/torch_geometric/deprecation.py:12: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "test_loader = loader = DataLoader(dataset, batch_size=args.batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "199bef6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], batch=[2708], ptr=[2])\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "batch_i = 0\n",
    "for batch in loader:\n",
    "    print(batch)\n",
    "    batch_i = batch_i +1\n",
    "\n",
    "print(batch_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "697c1385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch_geometric.data.batch.DataBatch"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2618b1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Cora():\n",
      "======================\n",
      "Number of graphs: 1\n",
      "Number of features: 1433\n",
      "Number of classes: 7\n",
      "==============================================================\n",
      "Number of nodes: 2708\n",
      "Number of node features: 1433\n",
      "Number of edges: 10556\n",
      "Number of edge features: 0\n",
      "Average node degree: 7.80\n",
      "========= split ======\n",
      "Number of training nodes: 140\n",
      "Training node label rate: 0.05\n",
      "Number of validation nodes: 500\n",
      "validation node label rate: 0.18\n",
      "Number of test nodes: 1000\n",
      "test node label rate: 0.37\n",
      "======== properties =======\n",
      "Contains isolated nodes: False\n",
      "Contains self-loops: False\n",
      "Is undirected: True\n",
      "Is directed: False\n"
     ]
    }
   ],
   "source": [
    "data = dataset[0]\n",
    "\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('======================')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "print('==============================================================')\n",
    "\n",
    "# Gather some statistics about the graph.\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of node features: {data.num_node_features}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Number of edge features: {data.num_edge_features}')\n",
    "print(f'Average node degree: {(2*data.num_edges) / data.num_nodes:.2f}')\n",
    "\n",
    "print(\"============= split ==========\")\n",
    "\n",
    "print(f'Number of training nodes: {data.train_mask.sum()}')\n",
    "print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}')\n",
    "print(f'Number of validation nodes: {data.val_mask.sum()}')\n",
    "print(f'validation node label rate: {int(data.val_mask.sum()) / data.num_nodes:.2f}')\n",
    "print(f'Number of test nodes: {data.test_mask.sum()}')\n",
    "print(f'test node label rate: {int(data.test_mask.sum()) / data.num_nodes:.2f}')\n",
    "\n",
    "print(\"============ properties ===========\")\n",
    "print(f'Contains isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Contains self-loops: {data.has_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')\n",
    "print(f'Is directed: {data.is_directed()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e6ad5a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['val_mask', 'y', 'edge_index', 'train_mask', 'batch', 'ptr', 'test_mask', 'x']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9bb219d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   0, 2708])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.ptr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a85149b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,    0,    0,  ..., 2707, 2707, 2707],\n",
       "        [ 633, 1862, 2582,  ...,  598, 1473, 2706]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.edge_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc218834",
   "metadata": {},
   "source": [
    "`batch.edge_index[0]`: from node i\n",
    "\n",
    "`batch.edge_index[1]`: to node j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "50af1281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 633, 1862, 2582,  ...,  598, 1473, 2706])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.edge_index[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5f8fc99f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([   0,    1,    2,  ..., 2705, 2706, 2707]),\n",
       " tensor([3, 3, 5,  ..., 1, 4, 4]))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.edge_index[0].unique(return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f9e38d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2708])\n",
      "torch.Size([2708])\n"
     ]
    }
   ],
   "source": [
    "print(batch.edge_index[0].unique(return_counts=True)[0].shape)\n",
    "print(batch.edge_index[0].unique(return_counts=True)[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "49748a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2708])\n",
      "torch.Size([2708])\n"
     ]
    }
   ],
   "source": [
    "print(batch.edge_index[1].unique(return_counts=True)[0].shape)\n",
    "print(batch.edge_index[1].unique(return_counts=True)[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e1916c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
       "          15,  16,  17,  18,  19,  21,  22,  23,  26,  29,  30,  31,  32,  33,\n",
       "          34,  36,  40,  42,  44,  65,  74,  78, 168]),\n",
       " tensor([485, 583, 553, 389, 281, 131,  82,  57,  25,  26,  14,  18,   5,   6,\n",
       "           6,   7,   8,   3,   5,   3,   1,   3,   1,   1,   2,   1,   2,   1,\n",
       "           1,   1,   1,   1,   1,   1,   1,   1,   1]))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.edge_index[0].unique(return_counts=True)[1].unique(return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9e72187a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
       "          15,  16,  17,  18,  19,  21,  22,  23,  26,  29,  30,  31,  32,  33,\n",
       "          34,  36,  40,  42,  44,  65,  74,  78, 168]),\n",
       " tensor([485, 583, 553, 389, 281, 131,  82,  57,  25,  26,  14,  18,   5,   6,\n",
       "           6,   7,   8,   3,   5,   3,   1,   3,   1,   1,   2,   1,   2,   1,\n",
       "           1,   1,   1,   1,   1,   1,   1,   1,   1]))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.edge_index[1].unique(return_counts=True)[1].unique(return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d248dbda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], batch=[2708], ptr=[2])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8220f854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True,  True,  ..., False, False, False])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.train_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fd8712b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([False,  True]), tensor([2568,  140]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.train_mask.unique(return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cee4895e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([False,  True]), tensor([2208,  500]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.val_mask.unique(return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8dba602a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([False,  True]), tensor([1708, 1000]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.test_mask.unique(return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ed069be1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.batch.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9b2f53bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   0, 2708])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.ptr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3611fe13",
   "metadata": {},
   "source": [
    "`x=[2708, 1433]`: `[num_nodes, num_node_features]` Each publication in the dataset is described by a 0/1-valued word vector indicating the absence/presence of the corresponding word from the dictionary. The dictionary consists of 1433 unique words.\n",
    "\n",
    "`edge_index=[2, 10556]`: Graph connectivity in COO format with shape [2, num_edges] and type torch.long If :obj:`edge_index` is of type :obj:`torch.LongTensor`, its shape must be defined as :obj:`[2, num_messages]`, where messages from nodes in :obj:`edge_index[0]` are sent to nodes in :obj:`edge_index[1]` [source](https://github.com/pyg-team/pytorch_geometric/blob/master/torch_geometric/nn/conv/message_passing.py)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3be1524",
   "metadata": {},
   "source": [
    "## GNN Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65b68dc",
   "metadata": {},
   "source": [
    "### Implementing Layer Modules\n",
    "\n",
    "In Colab 2, we implemented a GCN model for node and graph classification tasks. However, for that notebook we took advantage of PyG's built in GCN module. For Colab 3, we provide a build upon a general Graph Neural Network Stack, into which we will be able to plugin our own module implementations: GraphSAGE and GAT.\n",
    "\n",
    "We will then use our layer implemenations to complete node classification on the CORA dataset, a standard citation network benchmark. In this dataset, nodes correspond to documents and edges correspond to undirected citations. Each node or document in the graph is assigned a class label and features based on the documents binarized bag-of-words representation. Specifically, the Cora graph has 2708 nodes, 5429 edges, 7 prediction classes, and 1433 features per node. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e202c718",
   "metadata": {},
   "source": [
    "### GNN Stack Module\n",
    "\n",
    "Below is the implementation of a general GNN stack, where we can plugin any GNN layer, such as **GraphSage**, **GAT**, etc. This module is provided for you. Your implementations of the **GraphSage** and **GAT** (Colab 4) layers will function as components in the GNNStack Module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ddc8a348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_scatter\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric.nn as pyg_nn\n",
    "import torch_geometric.utils as pyg_utils\n",
    "\n",
    "from torch import Tensor\n",
    "from typing import Union, Tuple, Optional\n",
    "from torch_geometric.typing import (OptPairTensor, Adj, Size, NoneType,\n",
    "                                    OptTensor)\n",
    "\n",
    "from torch.nn import Parameter, Linear\n",
    "from torch_sparse import SparseTensor, set_diag\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.utils import remove_self_loops, add_self_loops, softmax\n",
    "\n",
    "class GNNStack(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, args, emb=False):\n",
    "        super(GNNStack, self).__init__()\n",
    "        conv_model = self.build_conv_model(args.model_type)\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.convs.append(conv_model(input_dim, hidden_dim))\n",
    "        assert (args.num_layers >= 1), 'Number of layers is not >=1'\n",
    "        for l in range(args.num_layers-1):\n",
    "            self.convs.append(conv_model(args.heads * hidden_dim, hidden_dim))\n",
    "\n",
    "        # post-message-passing\n",
    "        self.post_mp = nn.Sequential(\n",
    "            nn.Linear(args.heads * hidden_dim, hidden_dim), nn.Dropout(args.dropout), \n",
    "            nn.Linear(hidden_dim, output_dim))\n",
    "\n",
    "        self.dropout = args.dropout\n",
    "        self.num_layers = args.num_layers\n",
    "\n",
    "        self.emb = emb\n",
    "\n",
    "    def build_conv_model(self, model_type):\n",
    "        if model_type == 'GraphSage':\n",
    "            return GraphSage\n",
    "        elif model_type == 'GAT':\n",
    "            # When applying GAT with num heads > 1, you need to modify the \n",
    "            # input and output dimension of the conv layers (self.convs),\n",
    "            # to ensure that the input dim of the next layer is num heads\n",
    "            # multiplied by the output dim of the previous layer.\n",
    "            # HINT: In case you want to play with multiheads, you need to change the for-loop that builds up self.convs to be\n",
    "            # self.convs.append(conv_model(hidden_dim * num_heads, hidden_dim)), \n",
    "            # and also the first nn.Linear(hidden_dim * num_heads, hidden_dim) in post-message-passing.\n",
    "            return GAT\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "          \n",
    "        for i in range(self.num_layers):\n",
    "            x = self.convs[i](x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout,training=self.training)\n",
    "\n",
    "        x = self.post_mp(x)\n",
    "\n",
    "        if self.emb == True:\n",
    "            return x\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "    def loss(self, pred, label):\n",
    "        return F.nll_loss(pred, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d7b4e3",
   "metadata": {},
   "source": [
    "### Creating Our Own Message Passing Layer\n",
    "\n",
    "Now let's start implementing our own message passing layers! Working through this part will help us become acutely familiar with the behind the scenes work of implementing Pytorch Message Passing Layers, allowing us to build our own GNN models. To do so, we will work with and implement 3 critcal functions needed to define a PyG Message Passing Layer: `forward`, `message`, and `aggregate`.\n",
    "\n",
    "Before diving head first into the coding details, let us quickly review the key components of the message passing process. To do so, we will focus on a single round of messsage passing with respect to a single central node $x$. Before message passing, $x$ is associated with a feature vector $x^{l-1}$, and the goal of message passing is to update this feature vector as $x^l$. To do so, we implement the following steps: \n",
    "    \n",
    "1. each neighboring node $v$ passes its current message $v^{l-1}$ across the edge $(x, v)$ \n",
    "\n",
    "2. for the node $x$, we aggregate all of the messages of the neighboring nodes (for example through a sum or mean)\n",
    "\n",
    "3. we transform the aggregated information by for example applying linear and non-linear transformations. \n",
    "\n",
    "Altogether, the message passing process is applied such that every node $u$ in our graph updates its embedding by acting as the central node $x$ in step 1-3 described above. \n",
    "\n",
    "Now, we extending this process to that of a single message passing layer, the job of a message passing layer is to update the current feature representation or embedding of each node in a graph by propagating and transforming information within the graph. Overall, the general paradigm of a message passing layers is: 1) pre-processing -> 2) **message passing** / propagation -> 3) post-processing. \n",
    "\n",
    "The `forward` fuction that we will implement for our message passing layer captures this execution logic. Namely, the `forward` function handles the pre and post-processing of node features / embeddings, as well as initiates message passing by calling the `propagate` function. \n",
    "\n",
    "\n",
    "The `propagate` function encapsulates the message passing process! It does so by calling three important functions: 1) `message`, 2) `aggregate`, and 3) `update`. Our implementation will vary slightly from this, as we will not explicitly implement `update`, but instead place the logic for updating node embeddings after message passing and within the `forward` function. To be more specific, after information is propagated (message passing), we can further transform the node embeddings outputed by `propagate`. Therefore, the output of `forward` is exactly the node embeddings after one GNN layer.\n",
    "\n",
    "Lastly, before starting to implement our own layer, let us dig a bit deeper into each of the functions described above:\n",
    "\n",
    "1. \n",
    "\n",
    "```\n",
    "def propagate(edge_index, x=(x_i, x_j), extra=(extra_i, extra_j), size=size):\n",
    "```\n",
    "Calling `propagate` initiates the message passing process. Looking at the function parameters, we highlight a couple of key parameters. \n",
    "\n",
    "  - `edge_index` is passed to the forward function and captures the edge structure of the graph.\n",
    "  - `x=(x_i, x_j)` represents the node features that will be used in message passing. In order to explain why we pass the tuple `(x_i, x_j)`, we first look at how our edges are represented. For every edge $(i, j) \\in \\mathcal{E}$, we can differentiate $i$ as the source or central node ($x_{central}$) and j as the neighboring node ($x_{neighbor}$). \n",
    "  \n",
    "    Taking the example of message passing above, for a central node $u$ we will aggregate and transform all of the messages associated with the nodes $v$ s.t. $(u, v) \\in \\mathcal{E}$ (i.e. $v \\in \\mathcal{N}_{u}$). Thus we see, the subscripts `_i` and `_j` allow us to specifcally differenciate features associated with central nodes (i.e. nodes  recieving message information) and neighboring nodes (i.e. nodes passing messages). \n",
    "\n",
    "    This is definitely a somewhat confusing concept; however, one key thing to remember / wrap your head around is that depending on the perspective, a node $x$ acts as a central node or a neighboring node. In fact, in undirected graphs we store both edge directions (i.e. $(i, j)$ and $(j, i)$). From the central node perspective, `x_i`, x is collecting neighboring information to update its embedding. From a neighboring node perspective, `x_j`, x is passing its message information along the edge connecting it to a different central node.\n",
    "\n",
    "  - `extra=(extra_i, extra_j)` represents additional information that we can associate with each node beyond its current feature embedding. In fact, we can include as many additional parameters of the form `param=(param_i, param_j)` as we would like. Again, we highlight that indexing with `_i` and `_j` allows us to differentiate central and neighboring nodes. \n",
    "\n",
    "  The output of the `propagate` function is a matrix of node embeddings after the message passing process and has shape $[N, d]$.\n",
    "\n",
    "2. \n",
    "```\n",
    "def message(x_j, ...):\n",
    "```\n",
    "The `message` function is called by propagate and constructs the messages from\n",
    "neighboring nodes $j$ to central nodes $i$ for each edge $(i, j)$ in *edge_index*. This function can take any argument that was initially passed to `propagate`. Furthermore, we can again differentiate central nodes and neighboring nodes by appending `_i` or `_j` to the variable name, .e.g. `x_i` and `x_j`. Looking more specifically at the variables, we have:\n",
    "\n",
    "  - `x_j` represents a matrix of feature embeddings for all neighboring nodes passing their messages along their respective edge (i.e. all nodes $j$ for edges $(i, j) \\in \\mathcal{E}$). Thus, its shape is $[|\\mathcal{E}|, d]$!\n",
    "  - In implementing GAT we will see how to access additional variables passed to propagate\n",
    "\n",
    "  Critically, we see that the output of the `message` function is a matrix of neighboring node embeddings ready to be aggregated, having shape $[|\\mathcal{E}|, d]$.\n",
    "\n",
    "3. \n",
    "```\n",
    "def aggregate(self, inputs, index, dim_size = None):\n",
    "```\n",
    "Lastly, the `aggregate` function is used to aggregate the messages from neighboring nodes. Looking at the parameters we highlight:\n",
    "\n",
    "  - `inputs` represents a matrix of the messages passed from neighboring nodes (i.e. the output of the `message` function).\n",
    "  - `index` has the same shape as `inputs` and tells us the central node that corresponding to each of the rows / messages $j$ in the `inputs` matrix. Thus, `index` tells us which rows / messages to aggregate for each central node.\n",
    "\n",
    "  The output of `aggregate` is of shape $[N, d]$.\n",
    "\n",
    "\n",
    "For additional resources refer to the PyG documentation for implementing custom message passing layers: https://pytorch-geometric.readthedocs.io/en/latest/notes/create_gnn.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251a0006",
   "metadata": {},
   "source": [
    "### GraphSage Implementation\n",
    "\n",
    "For our first GNN layer, we will implement the well known GraphSage ([Hamilton et al. (2017)](https://arxiv.org/abs/1706.02216)) layer! \n",
    "\n",
    "For a given *central* node $v$ with current embedding $h_v^{l-1}$, the message passing update rule to tranform $h_v^{l-1} \\rightarrow h_v^l$ is as follows: \n",
    "\n",
    "\\begin{equation}\n",
    "h_v^{(l)} = W_l\\cdot h_v^{(l-1)} + W_r \\cdot AGG(\\{h_u^{(l-1)}, \\forall u \\in N(v) \\})\n",
    "\\end{equation}\n",
    "\n",
    "where $W_1$ and $W_2$ are learanble weight matrices and the nodes $u$ are *neighboring* nodes. Additionally, we use mean aggregation for simplicity:\n",
    "\n",
    "\\begin{equation}\n",
    "AGG(\\{h_u^{(l-1)}, \\forall u \\in N(v) \\}) = \\frac{1}{|N(v)|} \\sum_{u\\in N(v)} h_u^{(l-1)}\n",
    "\\end{equation}\n",
    "\n",
    "One thing to note is that we're adding a **skip connection** to our GraphSage implementation through the term $W_l\\cdot h_v^{(l-1)}$. \n",
    "\n",
    "Before implementing this update rule, we encourage you to think about how different parts of the formulas above correspond with the functions outlined earlier: 1) `forward`, 2) `message`, and 3) `aggregate`. As a hint, we are given what the aggregation function is (i.e. mean aggregation)! Now the question remains, what are the messages passed by each neighbor nodes and when do we call the `propagate` function? \n",
    "\n",
    "Note: in this case the message function or messages are actually quite simple. Additionally, remember that the `propagate` function encapsulates the operations of / the outputs of the combined `message` and `aggregate` functions.\n",
    "\n",
    "\n",
    "Lastly, $\\ell$-2 normalization of the node embeddings is applied after each iteration.\n",
    "\n",
    "\n",
    "<font color='red'>For the following questions, DON'T refer to any existing implementations online.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c669d099",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphSage(MessagePassing):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, normalize = True,\n",
    "                 bias = False, **kwargs):  \n",
    "        super(GraphSage, self).__init__(**kwargs)\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.normalize = normalize\n",
    "\n",
    "        self.lin_l = None\n",
    "        self.lin_r = None\n",
    "\n",
    "        ############################################################################\n",
    "        # TODO: Your code here! \n",
    "        # Define the layers needed for the message and update functions below.\n",
    "        # self.lin_l is the linear transformation that you apply to embedding \n",
    "        #            for central node.\n",
    "        # self.lin_r is the linear transformation that you apply to aggregated \n",
    "        #            message from neighbors.\n",
    "        # Don't forget the bias!\n",
    "        # Our implementation is ~2 lines, but don't worry if you deviate from this.\n",
    "        \n",
    "        print(f\"in_channels: {self.in_channels}\")\n",
    "        print(f\"out_channels: {self.out_channels}\")\n",
    "        \n",
    "        self.lin_l = nn.Linear(self.in_channels, self.out_channels, bias=True)\n",
    "        self.lin_r = nn.Linear(self.in_channels, self.out_channels, bias=True)\n",
    "\n",
    "        ############################################################################\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.lin_l.reset_parameters()\n",
    "        self.lin_r.reset_parameters()\n",
    "\n",
    "    def forward(self, x, edge_index, size = None):\n",
    "        \"\"\"\"\"\"\n",
    "\n",
    "        out = None\n",
    "\n",
    "        ############################################################################\n",
    "        # TODO: Your code here! \n",
    "        # Implement message passing, as well as any post-processing (our update rule).\n",
    "        # 1. Call the propagate function to conduct the message passing.\n",
    "        #    1.1 See the description of propagate above or the following link for more information: \n",
    "        #        https://pytorch-geometric.readthedocs.io/en/latest/notes/create_gnn.html\n",
    "        #    1.2 We will only use the representation for neighbor nodes (x_j), so by default\n",
    "        #        we pass the same representation for central and neighbor nodes as x=(x, x). \n",
    "        # 2. Update our node embedding with skip connection from the previous layer.\n",
    "        # 3. If normalize is set, do L-2 normalization (defined in \n",
    "        #    torch.nn.functional)\n",
    "        #\n",
    "        # Our implementation is ~5 lines, but don't worry if you deviate from this.\n",
    "        \n",
    "        # 1. Call the propagate function to conduct the message passing.\n",
    "        # 1.2 we pass the same representation for central and neighbor nodes as x=(x, x)\n",
    "        print()\n",
    "        print()\n",
    "        print(\"=============== in SAGE layer ===============\")\n",
    "        print(\"feed edge_index and x to a propagate func\")\n",
    "        print(f\"edge_index shape : {edge_index.shape}\")\n",
    "        print(f\"in x=(x, x), x shape : {x.shape}\")\n",
    "        print(\"x\")\n",
    "        print(x)\n",
    "        print(\"========= start propagate ========\")\n",
    "        \n",
    "        prop = self.propagate(edge_index, x=(x, x), size=size)\n",
    "        \n",
    "        print(\"===== propagate output ====\")\n",
    "        print(prop)\n",
    "        print(prop.shape)\n",
    "\n",
    "        # 2. Update our node embedding with skip connection from the previous layer.\n",
    "        out = self.lin_l(x) + self.lin_r(prop)\n",
    "        \n",
    "        print(\"====== lin_l(x) ====\")\n",
    "        print(self.lin_l(x))\n",
    "        print(self.lin_l(x).shape)\n",
    "        print(\"====== lin_r(prop) ====\")\n",
    "        print(self.lin_r(prop))\n",
    "        print(self.lin_r(prop).shape)\n",
    "        print(\"====== out = self.lin_l(x) + self.lin_r(prop) ====\")\n",
    "        print(out)\n",
    "        print(out.shape)\n",
    "        \n",
    "        \n",
    "\n",
    "        # 3. If normalize is set, do L-2 normalization \n",
    "        if self.normalize:\n",
    "            out = torch.nn.functional.normalize(out, p=2)\n",
    "        \n",
    "        print(\"==== out after norm ====\")\n",
    "        print(out)\n",
    "        print(out.shape)\n",
    "        ############################################################################\n",
    "\n",
    "        return out\n",
    "\n",
    "    def message(self, x_j):\n",
    "\n",
    "        out = None\n",
    "\n",
    "        ############################################################################\n",
    "        # TODO: Your code here! \n",
    "        # Implement your message function here.\n",
    "        # Hint: Look at the formulation of the mean aggregation function, focusing on \n",
    "        # what message each neighboring node passes.\n",
    "        #\n",
    "        # Our implementation is ~1 lines, but don't worry if you deviate from this.\n",
    "        \n",
    "        out = x_j\n",
    "        print(\"message: out = x_j\")\n",
    "        print(f\"message out shape {out.shape}\")\n",
    "        print(f\"message out {out}\")\n",
    "        \n",
    "        ############################################################################\n",
    "\n",
    "        return out\n",
    "\n",
    "    def aggregate(self, inputs, index, dim_size = None):\n",
    "\n",
    "        out = None\n",
    "\n",
    "        # The axis along which to index number of nodes.\n",
    "        node_dim = self.node_dim\n",
    "\n",
    "        ############################################################################\n",
    "        # TODO: Your code here! \n",
    "        # Implement your aggregate function here.\n",
    "        # See here as how to use torch_scatter.scatter: \n",
    "        # https://pytorch-scatter.readthedocs.io/en/latest/functions/scatter.html#torch_scatter.scatter\n",
    "        #\n",
    "        # Our implementation is ~1 lines, but don't worry if you deviate from this.\n",
    "        print(\"======= in aggregate func =======\")\n",
    "        print(f\"inputs.shape: {inputs.shape}\")\n",
    "        print(inputs)\n",
    "        print(f\"index.shape: {index.shape}\")\n",
    "        print(index)\n",
    "        print(f\"node_dim: {node_dim}\")\n",
    "        print(f\"dim_size: {dim_size}\")\n",
    "        \n",
    "        out = torch_scatter.scatter(inputs, index, node_dim, dim_size=dim_size, reduce='mean')\n",
    "        \n",
    "        print(f\"aggreate out shape {out.shape}\")\n",
    "        print(f\"aggregate out {out}\")\n",
    "        \n",
    "        ############################################################################\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d8897e",
   "metadata": {},
   "source": [
    "MessagePassing\n",
    "\n",
    "> propagate(edge_index: Union[Tensor, SparseTensor], size: Optional[Tuple[int, int]] = None, **kwargs)\n",
    "\n",
    "The initial call to start propagating messages.\n",
    "\n",
    "PARAMETERS\n",
    "\n",
    "* edge_index (Tensor or SparseTensor) – A torch.LongTensor or a torch_sparse.SparseTensor that defines the underlying graph connectivity/message passing flow. edge_index holds the indices of a general (sparse) assignment matrix of shape [N, M]. If edge_index is of type torch.LongTensor, its shape must be defined as [2, num_messages], where messages from nodes in edge_index[0] are sent to nodes in edge_index[1] (in case flow=\"source_to_target\"). If edge_index is of type torch_sparse.SparseTensor, its sparse indices (row, col) should relate to row = edge_index[1] and col = edge_index[0]. The major difference between both formats is that we need to input the transposed sparse adjacency matrix into propagate().\n",
    "\n",
    "\n",
    "* size (tuple, optional) – The size (N, M) of the assignment matrix in case edge_index is a LongTensor. If set to None, the size will be automatically inferred and assumed to be quadratic. This argument is ignored in case edge_index is a torch_sparse.SparseTensor. (default: None)\n",
    "\n",
    "\n",
    "* **kwargs – Any additional data which is needed to construct and aggregate messages, and to update node embeddings.\n",
    "\n",
    "From [official docs](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html?highlight=MessagePassing#torch_geometric.nn.conv.MessagePassing.propagate) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dca0b7",
   "metadata": {},
   "source": [
    "### Building Optimizers\n",
    "\n",
    "This function has been implemented for you. **For grading purposes please use the default Adam optimizer**, but feel free to play with other types of optimizers on your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3f79e451",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def build_optimizer(args, params):\n",
    "    weight_decay = args.weight_decay\n",
    "    filter_fn = filter(lambda p : p.requires_grad, params)\n",
    "    if args.opt == 'adam':\n",
    "        optimizer = optim.Adam(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
    "    elif args.opt == 'sgd':\n",
    "        optimizer = optim.SGD(filter_fn, lr=args.lr, momentum=0.95, weight_decay=weight_decay)\n",
    "    elif args.opt == 'rmsprop':\n",
    "        optimizer = optim.RMSprop(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
    "    elif args.opt == 'adagrad':\n",
    "        optimizer = optim.Adagrad(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
    "    if args.opt_scheduler == 'none':\n",
    "        return None, optimizer\n",
    "    elif args.opt_scheduler == 'step':\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=args.opt_decay_step, gamma=args.opt_decay_rate)\n",
    "    elif args.opt_scheduler == 'cos':\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.opt_restart)\n",
    "    return scheduler, optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c0aab9",
   "metadata": {},
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "721b7932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape as num_node_features: 1433\n",
      "hidden_dim: 32\n",
      "output as num_classes: 7\n"
     ]
    }
   ],
   "source": [
    "# build model\n",
    "print(f\"input shape as num_node_features: {dataset.num_node_features}\")\n",
    "print(f\"hidden_dim: {args.hidden_dim}\")\n",
    "print(f\"output as num_classes: {dataset.num_classes}\")\n",
    "model = GNNStack(dataset.num_node_features, args.hidden_dim, dataset.num_classes, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f7011a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GNNStack(\n",
       "  (convs): ModuleList(\n",
       "    (0): GraphSage(1433, 32)\n",
       "    (1): GraphSage(32, 32)\n",
       "  )\n",
       "  (post_mp): Sequential(\n",
       "    (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (1): Dropout(p=0.5, inplace=False)\n",
       "    (2): Linear(in_features=32, out_features=7, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "7eb07ccb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=============== in SAGE layer ===============\n",
      "feed edge_index and x to a propagate func\n",
      "edge_index shape : torch.Size([2, 10556])\n",
      "in x=(x, x), x shape : torch.Size([2708, 1433])\n",
      "x\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "========= start propagate ========\n",
      "message: out = x_j\n",
      "message out shape torch.Size([10556, 1433])\n",
      "message out tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "======= in aggregate func =======\n",
      "inputs.shape: torch.Size([10556, 1433])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "index.shape: torch.Size([10556])\n",
      "tensor([ 633, 1862, 2582,  ...,  598, 1473, 2706])\n",
      "node_dim: -2\n",
      "dim_size: 2708\n",
      "aggreate out shape torch.Size([2708, 1433])\n",
      "aggregate out tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.3333, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "===== propagate output ====\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.3333, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "torch.Size([2708, 1433])\n",
      "====== lin_l(x) ====\n",
      "tensor([[-0.0238,  0.0213, -0.0638,  ..., -0.0295,  0.0175, -0.0429],\n",
      "        [ 0.0611, -0.0342,  0.0452,  ..., -0.0642, -0.0178,  0.0382],\n",
      "        [ 0.0745,  0.0330, -0.0209,  ..., -0.0977,  0.0555,  0.0451],\n",
      "        ...,\n",
      "        [-0.0395, -0.0549,  0.1071,  ..., -0.1255,  0.0791,  0.0837],\n",
      "        [-0.0856, -0.0493, -0.0133,  ...,  0.0126, -0.0247,  0.0684],\n",
      "        [ 0.0017, -0.0862,  0.0419,  ..., -0.1352,  0.1268, -0.0640]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "torch.Size([2708, 32])\n",
      "====== lin_r(prop) ====\n",
      "tensor([[-0.1018, -0.0459,  0.0322,  ...,  0.0382,  0.0011,  0.0008],\n",
      "        [-0.0375, -0.0350, -0.0479,  ...,  0.1185,  0.0165,  0.0515],\n",
      "        [-0.0323, -0.0630, -0.0034,  ...,  0.0931,  0.0154,  0.0023],\n",
      "        ...,\n",
      "        [-0.0562,  0.0018, -0.0267,  ..., -0.0255, -0.0215,  0.0211],\n",
      "        [-0.0594,  0.0306,  0.0204,  ...,  0.0471, -0.0069,  0.0195],\n",
      "        [-0.0206, -0.0271, -0.0202,  ...,  0.0402,  0.0126,  0.0527]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "torch.Size([2708, 32])\n",
      "====== out = self.lin_l(x) + self.lin_r(prop) ====\n",
      "tensor([[-0.1256, -0.0246, -0.0316,  ...,  0.0086,  0.0186, -0.0421],\n",
      "        [ 0.0235, -0.0692, -0.0026,  ...,  0.0543, -0.0013,  0.0896],\n",
      "        [ 0.0422, -0.0300, -0.0243,  ..., -0.0047,  0.0709,  0.0474],\n",
      "        ...,\n",
      "        [-0.0956, -0.0531,  0.0805,  ..., -0.1510,  0.0576,  0.1049],\n",
      "        [-0.1450, -0.0186,  0.0071,  ...,  0.0597, -0.0315,  0.0879],\n",
      "        [-0.0189, -0.1133,  0.0217,  ..., -0.0950,  0.1393, -0.0113]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "torch.Size([2708, 32])\n",
      "==== out after norm ====\n",
      "tensor([[-0.3560, -0.0698, -0.0894,  ...,  0.0244,  0.0527, -0.1192],\n",
      "        [ 0.0477, -0.1402, -0.0053,  ...,  0.1101, -0.0027,  0.1818],\n",
      "        [ 0.0836, -0.0594, -0.0481,  ..., -0.0092,  0.1403,  0.0938],\n",
      "        ...,\n",
      "        [-0.2145, -0.1190,  0.1805,  ..., -0.3387,  0.1292,  0.2352],\n",
      "        [-0.3823, -0.0490,  0.0186,  ...,  0.1574, -0.0831,  0.2319],\n",
      "        [-0.0506, -0.3024,  0.0580,  ..., -0.2535,  0.3718, -0.0301]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "torch.Size([2708, 32])\n",
      "\n",
      "\n",
      "=============== in SAGE layer ===============\n",
      "feed edge_index and x to a propagate func\n",
      "edge_index shape : torch.Size([2, 10556])\n",
      "in x=(x, x), x shape : torch.Size([2708, 32])\n",
      "x\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0489, 0.1053, 0.0000],\n",
      "        [0.0955, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.3635],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.3609,  ..., 0.0000, 0.2585, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0372,  ..., 0.0000, 0.0000, 0.4637],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "========= start propagate ========\n",
      "message: out = x_j\n",
      "message out shape torch.Size([10556, 32])\n",
      "message out tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0489, 0.1053, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0489, 0.1053, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0489, 0.1053, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       grad_fn=<IndexSelectBackward0>)\n",
      "======= in aggregate func =======\n",
      "inputs.shape: torch.Size([10556, 32])\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0489, 0.1053, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0489, 0.1053, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0489, 0.1053, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       grad_fn=<IndexSelectBackward0>)\n",
      "index.shape: torch.Size([10556])\n",
      "tensor([ 633, 1862, 2582,  ...,  598, 1473, 2706])\n",
      "node_dim: -2\n",
      "dim_size: 2708\n",
      "aggreate out shape torch.Size([2708, 32])\n",
      "aggregate out tensor([[0.1366, 0.0000, 0.2702,  ..., 0.0662, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0178,  ..., 0.0000, 0.0000, 0.2325],\n",
      "        [0.0523, 0.0000, 0.0000,  ..., 0.0589, 0.0000, 0.1591],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.5114,  ..., 0.0000, 0.0015, 0.0000],\n",
      "        [0.0469, 0.0000, 0.0566,  ..., 0.0486, 0.1136, 0.1477],\n",
      "        [0.0000, 0.0000, 0.1551,  ..., 0.0486, 0.0960, 0.3681]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "===== propagate output ====\n",
      "tensor([[0.1366, 0.0000, 0.2702,  ..., 0.0662, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0178,  ..., 0.0000, 0.0000, 0.2325],\n",
      "        [0.0523, 0.0000, 0.0000,  ..., 0.0589, 0.0000, 0.1591],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.5114,  ..., 0.0000, 0.0015, 0.0000],\n",
      "        [0.0469, 0.0000, 0.0566,  ..., 0.0486, 0.1136, 0.1477],\n",
      "        [0.0000, 0.0000, 0.1551,  ..., 0.0486, 0.0960, 0.3681]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "torch.Size([2708, 32])\n",
      "====== lin_l(x) ====\n",
      "tensor([[-0.1943,  0.0361, -0.0968,  ..., -0.2107, -0.0764, -0.2152],\n",
      "        [ 0.0394,  0.1453,  0.0528,  ..., -0.0477, -0.3741, -0.0937],\n",
      "        [-0.2415,  0.0594, -0.0882,  ..., -0.0073, -0.1450, -0.1623],\n",
      "        ...,\n",
      "        [-0.0528,  0.1546,  0.0620,  ..., -0.0799, -0.1507,  0.0599],\n",
      "        [ 0.0977,  0.0949,  0.2149,  ..., -0.1890, -0.3797, -0.1547],\n",
      "        [-0.0392,  0.1192, -0.1622,  ..., -0.1990, -0.2470, -0.0825]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "torch.Size([2708, 32])\n",
      "====== lin_r(prop) ====\n",
      "tensor([[ 0.0366,  0.0876,  0.0160,  ...,  0.0393, -0.2463, -0.3654],\n",
      "        [ 0.0363,  0.1100,  0.0801,  ...,  0.0931, -0.2176, -0.1604],\n",
      "        [ 0.1385,  0.1164,  0.0305,  ...,  0.0931, -0.1399, -0.2221],\n",
      "        ...,\n",
      "        [ 0.0352,  0.2556,  0.0862,  ...,  0.2520, -0.1839, -0.3007],\n",
      "        [ 0.0056,  0.1694,  0.0827,  ...,  0.0187, -0.2264, -0.3260],\n",
      "        [ 0.0151,  0.2502,  0.1282,  ...,  0.0715, -0.2360, -0.2464]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "torch.Size([2708, 32])\n",
      "====== out = self.lin_l(x) + self.lin_r(prop) ====\n",
      "tensor([[-0.1577,  0.1237, -0.0808,  ..., -0.1714, -0.3227, -0.5806],\n",
      "        [ 0.0758,  0.2553,  0.1329,  ...,  0.0455, -0.5917, -0.2542],\n",
      "        [-0.1030,  0.1758, -0.0577,  ...,  0.0858, -0.2849, -0.3844],\n",
      "        ...,\n",
      "        [-0.0176,  0.4102,  0.1482,  ...,  0.1722, -0.3346, -0.2408],\n",
      "        [ 0.1034,  0.2643,  0.2976,  ..., -0.1703, -0.6061, -0.4808],\n",
      "        [-0.0242,  0.3694, -0.0339,  ..., -0.1274, -0.4830, -0.3289]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "torch.Size([2708, 32])\n",
      "==== out after norm ====\n",
      "tensor([[-0.1150,  0.0901, -0.0589,  ..., -0.1249, -0.2352, -0.4232],\n",
      "        [ 0.0624,  0.2103,  0.1095,  ...,  0.0374, -0.4873, -0.2093],\n",
      "        [-0.0925,  0.1579, -0.0518,  ...,  0.0770, -0.2558, -0.3451],\n",
      "        ...,\n",
      "        [-0.0127,  0.2967,  0.1072,  ...,  0.1245, -0.2420, -0.1741],\n",
      "        [ 0.0788,  0.2015,  0.2268,  ..., -0.1299, -0.4620, -0.3665],\n",
      "        [-0.0175,  0.2682, -0.0247,  ..., -0.0925, -0.3507, -0.2388]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "torch.Size([2708, 32])\n"
     ]
    }
   ],
   "source": [
    "pred = model(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec36b1f",
   "metadata": {},
   "source": [
    "```\n",
    "=============== in SAGE layer ===============\n",
    "feed edge_index and x to a propagate func\n",
    "edge_index shape : torch.Size([2, 10556])\n",
    "in x=(x, x), x shape : torch.Size([2708, 1433])\n",
    "\n",
    "\n",
    "========= start propagate ========\n",
    "message: out = x_j\n",
    "message out shape torch.Size([10556, 1433])\n",
    "\n",
    "======= in aggregate func =======\n",
    "inputs.shape: torch.Size([10556, 1433])\n",
    "index.shape: torch.Size([10556])\n",
    "node_dim: -2\n",
    "dim_size: 2708\n",
    "aggreate out shape torch.Size([2708, 1433])\n",
    "\n",
    "===== propagate output ====\n",
    "torch.Size([2708, 1433])\n",
    "\n",
    "====== lin_l(x) ====\n",
    "torch.Size([2708, 32])\n",
    "====== lin_r(prop) ====\n",
    "torch.Size([2708, 32])\n",
    "====== out = self.lin_l(x) + self.lin_r(prop) ====\n",
    "torch.Size([2708, 32])\n",
    "==== out after norm ====\n",
    "torch.Size([2708, 32])\n",
    "\n",
    "\n",
    "=============== in SAGE layer ===============\n",
    "feed edge_index and x to a propagate func\n",
    "edge_index shape : torch.Size([2, 10556])\n",
    "in x=(x, x), x shape : torch.Size([2708, 32])\n",
    "\n",
    "========= start propagate ========\n",
    "message: out = x_j\n",
    "message out shape torch.Size([10556, 32])\n",
    "\n",
    "======= in aggregate func =======\n",
    "inputs.shape: torch.Size([10556, 32])\n",
    "index.shape: torch.Size([10556])\n",
    "tensor([ 633, 1862, 2582,  ...,  598, 1473, 2706])\n",
    "node_dim: -2\n",
    "dim_size: 2708\n",
    "aggreate out shape torch.Size([2708, 32])\n",
    "\n",
    "===== propagate output ====\n",
    "torch.Size([2708, 32])\n",
    "\n",
    "====== lin_l(x) ====\n",
    "torch.Size([2708, 32])\n",
    "====== lin_r(prop) ====\n",
    "torch.Size([2708, 32])\n",
    "====== out = self.lin_l(x) + self.lin_r(prop) ====\n",
    "torch.Size([2708, 32])\n",
    "==== out after norm ====\n",
    "torch.Size([2708, 32])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd34b93",
   "metadata": {},
   "source": [
    "### what happen in the model?\n",
    "\n",
    "1. the model got inputs (data). \n",
    "\n",
    "    `x=[2708, 1433]`: `[num_nodes, num_node_features]` for each publication, a dictionary of 1433 unique words.\n",
    "\n",
    "    `edge_index=[2, 10556]`: Graph connectivity in COO format with shape [2, num_edges] `[0]` as from, `[1]` as to, even there is no direction.\n",
    "\n",
    "\n",
    "2. the first GraphSAGE layer\n",
    "    2.1 propagate \n",
    "    \n",
    "    2.1.1 message\n",
    "        input size: [10556, 1433], output size: [10556, 1433] as [num_edges, num_node_features]\n",
    "        node features for each edge are seted. There is no manipulation applied.\n",
    "    2.1.2 aggregate\n",
    "        aggregate generated messages.\n",
    "        inputs\n",
    "            inputs.shape: [10556, 1433] as [num_edges, num_node_features]\n",
    "            index.shape: [10556] as [num_edges]\n",
    "        outputs\n",
    "            out.shape: [2708, 1433]\n",
    "            \n",
    "    <img src=\"https://raw.githubusercontent.com/rusty1s/pytorch_scatter/master/docs/source/_figures/add.svg\" width=\"400\">\n",
    "        \n",
    "from [source](https://pytorch-scatter.readthedocs.io/en/latest/functions/scatter.html#torch_scatter.scatter)\n",
    "    \n",
    "    \n",
    "    2.2 embedding\n",
    "        2.2.1 lin_l(x)\n",
    "            Linear take (*, input_dim) and return (*, output_dim)\n",
    "            input_dim = input shape = num_node_features: 1433\n",
    "            output_dim = hidden_dim: 32\n",
    "            \n",
    "            input: x = [2708, 1433] as [*, input_dim ]. In this case, * means the number of nodes\n",
    "            output: [2708, 32] as [*, hidden dim]\n",
    "            \n",
    "        2.2.2 lin_r(prop)\n",
    "            Linear take (*, input_dim) and return (*, output_dim)\n",
    "            input_dim = input shape = num_node_features: 1433\n",
    "            output_dim = hidden_dim: 32\n",
    "            \n",
    "            input: prop = [2708, 1433] is output of aggregate func with shape of [*, input_dim ]. In this case, * means the number of nodes\n",
    "            output: [2708, 32] as [num_nodes, hidden dim]\n",
    "    2.3 normalize\n",
    "        Same as other normalize operation.\n",
    "        the final out shape: [2708, 32]\n",
    "        \n",
    "Now, regard x as shape of [2708, 32] like each node has 32 features.\n",
    "\n",
    "3. the second GraphSAGE layer\n",
    "    3.1 propagate \n",
    "    \n",
    "    3.1.1 message\n",
    "        input size: [10556, 32], output size: [10556, 32] as [num_edges, hidden_dim]\n",
    "        node features for each edge are seted. There is no manipulation applied.\n",
    "    3.1.2 aggregate\n",
    "        aggregate generated messages.\n",
    "        inputs\n",
    "            inputs.shape: [10556, 32] as [num_edges, num_node_features]\n",
    "            index.shape: [10556] as [num_edges]\n",
    "        outputs\n",
    "            out.shape: [2708, 32]\n",
    "            \n",
    "    <img src=\"https://raw.githubusercontent.com/rusty1s/pytorch_scatter/master/docs/source/_figures/add.svg\" width=\"400\">\n",
    "        \n",
    "from [source](https://pytorch-scatter.readthedocs.io/en/latest/functions/scatter.html#torch_scatter.scatter)\n",
    "    \n",
    "    \n",
    "    2.2 embedding\n",
    "        2.2.1 lin_l(x)\n",
    "            Linear take (*, input_dim) and return (*, output_dim)\n",
    "            input_dim = input shape = hidden_dim: 32\n",
    "            output_dim = hidden_dim: 32\n",
    "            \n",
    "            input: x = [2708, 32] as [*, input_dim ]. In this case, * means the number of nodes\n",
    "            output: [2708, 32] as [*, hidden dim]\n",
    "            \n",
    "        2.2.2 lin_r(prop)\n",
    "            Linear take (*, input_dim) and return (*, output_dim)\n",
    "            input_dim = input shape = hidden_dim: 32\n",
    "            output_dim = hidden_dim: 32\n",
    "            \n",
    "            input: prop = [2708, 32] as output of aggregate func and shape of [*, input_dim ]. In this case, * means the number of nodes.\n",
    "            output: [2708, 32] as [num_nods, hidden dim] and shape of [*, hidden dim]\n",
    "    2.3 normalize\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd427f82",
   "metadata": {},
   "source": [
    "Other processes are similler to the usual MLP. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65d8685",
   "metadata": {},
   "source": [
    "## Training and Testing\n",
    "\n",
    "Here we provide you with the functions to train and test. **Please do not modify this part for grading purposes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8aed38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from tqdm import trange\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "import torch_geometric.nn as pyg_nn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def train(dataset, args):\n",
    "    \n",
    "    print(\"Node task. test set size:\", np.sum(dataset[0]['test_mask'].numpy()))\n",
    "    print()\n",
    "    test_loader = loader = DataLoader(dataset, batch_size=args.batch_size, shuffle=False)\n",
    "\n",
    "    # build model\n",
    "    model = GNNStack(dataset.num_node_features, args.hidden_dim, dataset.num_classes, \n",
    "                            args)\n",
    "    scheduler, opt = build_optimizer(args, model.parameters())\n",
    "\n",
    "    # train\n",
    "    losses = []\n",
    "    test_accs = []\n",
    "    best_acc = 0\n",
    "    best_model = None\n",
    "    for epoch in trange(args.epochs, desc=\"Training\", unit=\"Epochs\"):\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "        for batch in loader:\n",
    "            opt.zero_grad()\n",
    "            pred = model(batch)\n",
    "            label = batch.y\n",
    "            pred = pred[batch.train_mask]\n",
    "            label = label[batch.train_mask]\n",
    "            loss = model.loss(pred, label)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            total_loss += loss.item() * batch.num_graphs\n",
    "        total_loss /= len(loader.dataset)\n",
    "        losses.append(total_loss)\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "          test_acc = test(test_loader, model)\n",
    "          test_accs.append(test_acc)\n",
    "          if test_acc > best_acc:\n",
    "            best_acc = test_acc\n",
    "            best_model = copy.deepcopy(model)\n",
    "        else:\n",
    "          test_accs.append(test_accs[-1])\n",
    "    \n",
    "    return test_accs, losses, best_model, best_acc, test_loader\n",
    "\n",
    "def test(loader, test_model, is_validation=False, save_model_preds=False, model_type=None):\n",
    "    test_model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    # Note that Cora is only one graph!\n",
    "    for data in loader:\n",
    "        with torch.no_grad():\n",
    "            # max(dim=1) returns values, indices tuple; only need indices\n",
    "            pred = test_model(data).max(dim=1)[1]\n",
    "            label = data.y\n",
    "\n",
    "        mask = data.val_mask if is_validation else data.test_mask\n",
    "        # node classification: only evaluate on nodes in test set\n",
    "        pred = pred[mask]\n",
    "        label = label[mask]\n",
    "\n",
    "        if save_model_preds:\n",
    "          print (\"Saving Model Predictions for Model Type\", model_type)\n",
    "\n",
    "          data = {}\n",
    "          data['pred'] = pred.view(-1).cpu().detach().numpy()\n",
    "          data['label'] = label.view(-1).cpu().detach().numpy()\n",
    "\n",
    "          df = pd.DataFrame(data=data)\n",
    "          # Save locally as csv\n",
    "          df.to_csv('CORA-Node-' + model_type + '.csv', sep=',', index=False)\n",
    "            \n",
    "        correct += pred.eq(label).sum().item()\n",
    "\n",
    "    total = 0\n",
    "    for data in loader.dataset:\n",
    "        total += torch.sum(data.val_mask if is_validation else data.test_mask).item()\n",
    "\n",
    "    return correct / total\n",
    "  \n",
    "class objectview(object):\n",
    "    def __init__(self, d):\n",
    "        self.__dict__ = d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330290a1",
   "metadata": {},
   "source": [
    "## Let's Start the Training!\n",
    "\n",
    "We will be working on the CORA dataset on node-level classification.\n",
    "\n",
    "This part is implemented for you. **For grading purposes, please do not modify the default parameters.** However, feel free to play with different configurations just for fun!\n",
    "\n",
    "**Submit your best accuracy and loss on Gradescope.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86a7eecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\gnn\\lib\\site-packages\\torch_geometric\\deprecation.py:12: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node task. test set size: 1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████| 500/500 [00:26<00:00, 18.61Epochs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum test set accuracy: 0.803\n",
      "Minimum loss: 0.10081276297569275\n",
      "Saving Model Predictions for Model Type GraphSage\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAABMgUlEQVR4nO3dd3hUxfrA8e+k9x5qgID0XkITlIA0G/aCeu3ixV6vvVzu9apX7F4LKPYfdiyIAlIEpIbeIbRAKCmk9zK/P87ZzW52ExKyIbD7fp5nn+yZ0+Zsdt8zZ2bOHKW1RgghhPvyauoMCCGEaFwS6IUQws1JoBdCCDcngV4IIdycBHohhHBzEuiFEMLNSaAXQgg3J4FeeDyl1HVKqSSlVL5S6ohS6jel1PCmzpcQriKBXng0pdRDwBvAf4DmQFvgXeCSem7Hx+WZE8JFJNALj6WUCgemAHdrrX/QWhdorcu01r9orR9VSvkrpd5QSh02X28opfzNdROVUoeUUo8ppY4CHyulIpVSs5VS6UqpLPN9XJMepBBIoBeebSgQAMyqYf5TwBCgL9AHGAQ8bTO/BRAFtAMmYfyePjan2wJFwDuNkG8h6kXJWDfCUymlrgde1Vq3qGH+HuBerfUcc3oc8IHWOl4plQjMA8K01sU1rN8XWKS1jmyE7AtRZ1KvKDxZJhCjlPLRWpc7md8KOGAzfcBMs0i3DfJKqSDgdWA8YAnuoUopb611hWuzLkTdSdWN8GQrgBLg0hrmH8aohrFoa6ZZVL8cfhjoAgzWWocB55rpqsE5FaIBpEQvPJbWOkcp9SzwP6VUOUZVTBkwGhgJzASeVkqtwQjqzwJf1LLJUIx6+WylVBTwXGPmX4i6khK98Gha61eBhzAaWdOBg8A9wI/Av4EkYBOwGVhnptXkDSAQyABWAr83UraFqBdpjBVCCDcnJXohhHBzEuiFEMLNSaAXQgg3J4FeCCHc3GnZvTImJkbHx8c3dTaEEOKMsXbt2gytdayzeadloI+PjycpKampsyGEEGcMpdSBmuZJ1Y0QQri5EwZ6pVQbpdQipdQ2pdRWpdT9TpZRSqm3lFLJSqlNSqn+NvNuUkrtNl83ufoAhBBC1K4uVTflwMNa63VKqVBgrVJqvtZ6m80y5wOdzNdg4D1gsM1t4AkYt5CvVUr9rLXOculRCCGEqNEJA73W+ghwxHyfp5TaDrQGbAP9JcBn2rjNdqVSKkIp1RJIBOZrrY8DKKXmY4zsN9OlRyGEi5WVlXHo0CGKi52OQCxEkwkICCAuLg5fX986r1OvxlilVDzQD1hVbVZrjDFCLA6ZaTWlO9v2JIyHN9C2bdv6ZEsIlzt06BChoaHEx8ejlAw+KU4PWmsyMzM5dOgQ7du3r/N6dW6MVUqFAN8DD2itc08ij7XSWk/TWidorRNiY532EBLilCkuLiY6OlqCvDitKKWIjo6u95VmnQK9UsoXI8h/qbX+wckiqUAbm+k4M62mdCFOexLkxenoZL6Xdel1o4CPgO1a69dqWOxn4Eaz980QIMes258LjDUfmhwJjDXTXK64rIJpS/awPDmjMTYvhBBnrLqU6IcBfwNGKaU2mK8LlFJ/V0r93VxmDrAXSAamA3cBmI2w/wLWmK8ploZZV/P19mL60n18umJ/Y2xeiFMqOzubd99996TWveCCC8jOzq51mWeffZY//vjjpLZfXXx8PBkZp76A9dprr9G1a1d69epFnz59eOihhygrK3PJtp9//nmmTp3qdN4LL7xAjx496N27N3379mXVqupNlqefuvS6WcYJHoVm9ra5u4Z5M4AZJ5W7evD2UlzcuxVfrDxAbnEZYQF1b5EW4nRjCfR33XWXw7zy8nJ8fGr+6c6ZM+eE258yZUqD8tfU3n//febNm8fKlSuJiIigtLSU1157jaKiIofeKBUVFXh7e7tkvytWrGD27NmsW7cOf39/MjIyKC0tdcm2G5Nb3Rmb2CWW0opKtqa6vK1YiFPq8ccfZ8+ePfTt25dHH32UxYsXc8455zBhwgS6d+8OwKWXXsqAAQPo0aMH06ZNs65rKWHv37+fbt26cccdd9CjRw/Gjh1LUVERADfffDPfffeddfnnnnuO/v3706tXL3bs2AFAeno6Y8aMoUePHtx+++20a9fuhCX31157jZ49e9KzZ0/eeOMNAAoKCrjwwgvp06cPPXv25Ouvv7YeY/fu3enduzePPPJIvT6fF154gffee4+IiAgA/Pz8ePzxxwkLCwMgJCSEhx9+mD59+rBixQqmTJnCwIED6dmzJ5MmTcLywKXExETuv/9++vbtS8+ePVm9erV1H9u2bSMxMZEOHTrw1ltvAXDkyBFiYmLw9/cHICYmhlatjOfF17SPNWvWWEv/jz76KD179gSME9Cjjz7KwIED6d27Nx988EG9PoP6OC3HujlZnZuHArA7LY+hZ0U3cW6Eu/jnL1vZdti1hYfurcJ47uIeNc5/6aWX2LJlCxs2bABg8eLFrFu3ji1btli71c2YMYOoqCiKiooYOHAgV1xxBdHR9t/73bt3M3PmTKZPn87VV1/N999/zw033OCwv5iYGNatW8e7777L1KlT+fDDD/nnP//JqFGjeOKJJ/j999/56KOPaj2mtWvX8vHHH7Nq1Sq01gwePJgRI0awd+9eWrVqxa+//gpATk4OmZmZzJo1ix07dqCUOmFVk63c3Fzy8/Nr7V5YUFDA4MGDefXVVwHo3r07zz77LAB/+9vfmD17NhdffDEAhYWFbNiwgSVLlnDrrbeyZcsWAHbs2MGiRYvIy8ujS5cuTJ48mbFjxzJlyhQ6d+7M6NGjueaaaxgxYgQA99xzj9N93HLLLUyfPp2hQ4fy+OOPW/P40UcfER4ezpo1aygpKWHYsGGMHTu2Xt0m68qtSvTNw/wJ9fdh97H8ps6KEC43aNAguyDw1ltv0adPH4YMGcLBgwfZvXu3wzrt27enb9++AAwYMID9+/c73fbll1/usMyyZcu49tprARg/fjyRkZG15m/ZsmVcdtllBAcHExISwuWXX87SpUvp1asX8+fP57HHHmPp0qWEh4cTHh5OQEAAt912Gz/88ANBQUH1/DSqzJ07l759+xIfH8/y5csB8Pb25oorrrAus2jRIgYPHkyvXr1YuHAhW7dutc6bOHEiAOeeey65ubnWk86FF16Iv78/MTExNGvWjGPHjhESEsLatWuZNm0asbGxXHPNNXzyySc17iM7O5u8vDyGDh0KwHXXXWfd77x58/jss8/o27cvgwcPJjMz0+n/0BXcqkSvlKJLi1CW7k4nv6ScEH+3OjzRRGoreZ9KwcHB1veLFy/mjz/+YMWKFQQFBZGYmOi0b7WligGM4GepuqlpOW9vb8rLy12a786dO7Nu3TrmzJnD008/zXnnncezzz7L6tWrWbBgAd999x3vvPMOCxcutFtv3LhxHDt2jISEBD788ENrelhYGCEhIezbt4/27dszbtw4xo0bx0UXXWStLw8ICLDWyxcXF3PXXXeRlJREmzZteP755+0+q+rdFS3T1T87y+fi7e1NYmIiiYmJ9OrVi08//ZRrr7221n04o7Xm7bffZty4cfX9SOvNrUr0APeP7sT+zEK+XnPwxAsLcZoKDQ0lLy+vxvk5OTlERkYSFBTEjh07WLlypcvzMGzYML755hvAKH1mZdU+RNU555zDjz/+SGFhIQUFBcyaNYtzzjmHw4cPExQUxA033MCjjz7KunXryM/PJycnhwsuuIDXX3+djRs3Omxv7ty5bNiwwS7IWzzxxBNMnjzZWvrWWtcYWC3pMTEx5OfnW9smLCxtBsuWLbNebdRk586ddqXuDRs20K5duxr3ERERQWhoqLVnzldffWVdd9y4cbz33nvWnkK7du2ioKCgxn03hNsVec/pFMtZscEs3pnGbcNdX9clxKkQHR3NsGHD6NmzJ+effz4XXnih3fzx48fz/vvv061bN7p06cKQIUNcnofnnnuOiRMn8vnnnzN06FBatGhBaGhojcv379+fm2++mUGDBgFw++23069fP+bOncujjz6Kl5cXvr6+vPfee+Tl5XHJJZdQXFyM1prXXqvpFh3nJk+ebK2H9/f3JyQkhGHDhtGvXz+HZSMiIrjjjjvo2bMnLVq0YODAgXbzAwIC6NevH2VlZcyYUXsHwfz8fO69916ys7Px8fGhY8eOTJs2rdZ9fPTRR9xxxx14eXkxYsQI64nk9ttvZ//+/fTv3x+tNbGxsfz444/1+hzqSllahk8nCQkJuiEPHvnnL1v5clUK26eMx9tL7m4U9bd9+3a6devW1NloUiUlJXh7e+Pj48OKFSuYPHmytXHYXSQmJjJ16lQSEhIabR/5+fmEhIQARiP7kSNHePPNNxu0TWffT6XUWq210wNxuxI9wFmxIZSWV5KRX0LzsICmzo4QZ6SUlBSuvvpqKisr8fPzY/r06U2dpTPSr7/+yosvvkh5eTnt2rWzNt6eSm4Z6FtHBAJwKKtIAr0QJ6lTp06sX7++qbPRqBYvXtzo+7jmmmu45pprGn0/tXG7xliAVmagP5ztvIeBEEJ4EjcN9EYpXgK9EEK4aaAPDfAlLMCHvemN01VJCCHOJG4Z6AESuzTj961HKS6raOqsCCFEk3LbQD+hTytyisrYdCinqbMiRL01ZJhigDfeeIPCwkIX5ujMUF5ezpNPPkmnTp3o27cvffv25YUXXnDZ9m0Hg7NVWVnJfffdR8+ePenVqxcDBw5k3759LttvQ7ltoO/YzOi3mnLc877s4sznDoHe1UMp1MXTTz/N4cOH2bx5Mxs2bGDp0qVOx6jXWlNZWemy/X799dccPnyYTZs2sXnzZmbNmmUdWfN04LaBvlVEIF4KUjKlnl6ceaoPUwzwyiuvWIe0fe655wDnQwC/9dZbHD58mJEjRzJy5EiHbdc0nG5ycjKjR4+mT58+9O/fnz179gDw8ssvWx/uYRl9MTExEctNjRkZGcTHxwPwySefMGHCBEaNGsV5551Hfn4+5513nnUI5J9++smaj88++4zevXvTp08f/va3v5GXl0f79u2tgTk3N9du+kQKCwuZPn06b7/9NgEBRoeM0NBQnn/+eQD2799Ply5duPHGG+nZsycHDx5k8uTJJCQk0KNHD+tnCsbQzf/4xz/o1asXgwYNIjk52TpvyZIlnH322XTo0MFauj9y5AgtW7bEy8sIqXFxcdZB4Grax5w5c+jatSsDBgzgvvvu46KLLrL+T2+99VYGDRpEv3797D6zk+WW/egB/Hy8aBkeKCV60XC/PQ5HN7t2my16wfkv1Ti7+jDF8+bNY/fu3axevRqtNRMmTGDJkiWkp6c7DAEcHh7Oa6+9xqJFi4iJiXHYdk3D6V5//fU8/vjjXHbZZRQXF1NZWclvv/3GTz/9xKpVqwgKCuL48RM/IG7dunVs2rSJqKgoysvLmTVrFmFhYWRkZDBkyBAmTJjAtm3b+Pe//83y5cuJiYnh+PHjhIaGkpiYyK+//sqll17KV199xeWXX+7wIJGaJCcn07Zt21qHadi9ezeffvqpdciIF154gaioKCoqKjjvvPPYtGkTvXv3BiA8PJzNmzfz2Wef8cADDzB79mzACOrLli1jx44dTJgwgSuvvJKrr76a4cOHs3TpUs477zxuuOEG63AMzvbRuXNn7rzzTpYsWUL79u2tI2halh81ahQzZswgOzubQYMGMXr0aLtB7erLbUv0AG2jgjgggV64gXnz5jFv3jz69etH//792bFjB7t373Y6BPCJOBtONy8vj9TUVC677DLAGP8lKCiIP/74g1tuucU6jHBUVNQJtz9mzBjrclprnnzySXr37s3o0aNJTU3l2LFjLFy4kKuuusp6IrIsf/vtt/Pxxx8D8PHHH3PLLbfU/8Myffzxx/Tt25c2bdpw8KAxyGG7du3sxgX65ptv6N+/P/369WPr1q1s27bNOs8SfCdOnMiKFSus6ZdeeileXl50796dY8eOAUYJfufOnbz44ot4eXlx3nnnsWDBghr3sWPHDjp06GAddto20M+bN4+XXnqJvn37WkclTUlJOenPAepQoldKzQAuAtK01j2dzH8UuN5me92AWK31caXUfiAPqADKaxqHobF0ah7C92sPUVmp8ZIxb8TJqqXkfaporXniiSe48847HeY5GwK4JicasreufHx8rHXc1de3LXl++eWXpKens3btWnx9fYmPj691f8OGDWP//v0sXryYiooK69OYLCoqKhgwYAAAEyZMsHskYseOHUlJSSEvL4/Q0FBuueUWbrnlFnr27ElFRYVD3vbt28fUqVNZs2YNkZGR3HzzzTUOX2z73nb4Ytuxwvz9/Tn//PM5//zzad68OT/++CMdOnSodR/OaK35/vvv6dKlS63L1UddSvSfAONrydQrWuu+Wuu+wBPAn9UeAD7SnH9KgzxAj1ZhFJRWSKlenHGqD1M8btw4ZsyYQX6+8VCd1NRU0tLSnA4B7Gx9i5qG0w0NDSUuLs46emJJSQmFhYWMGTOGjz/+2Nqwa6m6iY+PZ+3atQBOe6FY5OTk0KxZM3x9fVm0aBEHDhwAYNSoUXz77bdkZmbabRfgxhtv5LrrrnNamvf29mbDhg1s2LDB4bm3QUFB3Hbbbdxzzz3W46yoqKjxma65ubkEBwcTHh7OsWPH+O233+zmW4Yv/vrrr60PDqnJunXrOHz4MGD0wNm0aRPt2rWrcR9dunRh79691oe8WPYFxv/67bfftp5EXDEMRV0eDr5EKRVfx+1NBGY2KEcu1KOVcRm79XAO7WNOvn5LiFOt+jDFr7zyCtu3b7cGnJCQEL744guSk5MdhgAGmDRpEuPHj6dVq1YsWrTIut3ahtP9/PPPufPOO3n22Wfx9fXl22+/Zfz48WzYsIGEhAT8/Py44IIL+M9//sMjjzzC1VdfzbRp0xyGULZ1/fXXc/HFF9OrVy8SEhLo2rUrAD169OCpp55ixIgReHt7069fP+tgX9dffz1PP/20XXVGXb3wwgs888wz9OzZk9DQUAIDA7npppto1aqVNRBb9OnTh379+tG1a1fatGnDsGHD7OZnZWXRu3dv/P39mTmz9rCWlpbGHXfcQUlJCWA8Deyee+6xDoFcfR+BgYG8++67jB8/nuDgYLv/wzPPPMMDDzxA7969qayspH379tb2gZNVp2GKzUA/21nVjc0yQcAhoKOlRK+U2gdkARr4QGs9rZb1JwGTANq2bTvAcuZviMLScro/O5fHxndlcuJZDd6e8BwyTHHT+e677/jpp5/4/PPPmywP8fHxJCUlOW3MdhXL8MVaa+6++246derEgw8+WKd1m3KY4ouBv6pV2wzXWqcqpZoB85VSO7TWS5ytbJ4EpoExHr0rMhTk50OArxfHC0pcsTkhRCO79957+e2335gzZ05TZ6XRTZ8+nU8//ZTS0lL69evntP3FVVwZ6K+lWrWN1jrV/JumlJoFDAKcBvrGEh3sT2aB8zo6IcTp5e23327qLADU+BB1V3rwwQfrXIJvKJd0r1RKhQMjgJ9s0oKVUqGW98BYYIsr9lcfUcF+HJdAL07C6fj0NSFO5ntZl+6VM4FEIEYpdQh4DvA1d/i+udhlwDytte1tqM2BWWa3JB/g/7TWv9c7hw0kgV6cjICAADIzM4mOjrbrWidEU9Jak5mZab3zt67q0uvmhE3fWutPMLph2qbtBfrUKzeNIDrYj+S0/KbOhjjDxMXFcejQIdLT05s6K0LYCQgIIC4url7ruO0QCBZSohcnw9fX13rXohBnOrceAgEgOsSforIK8ktO/Uh6QghxOnD7QB8XaXlQuNwdK4TwTG4f6NtEGYMxHTwuz48VQngm9w/0ZolehisWQngqtw/0UcF+BPt5c1ACvRDCQ7l9oFdK0SYqSOrohRAey+0DPUBcZJBU3QghPJZHBPq2UUEcPF4kt7QLITySRwT6NlGBFJVVyOBmQgiP5BmBPtLoYinVN0IIT+QRgT4m1HjGY5aU6IUQHsgjAn14oC8AOUVlTZwTIYQ49Twq0OdKoBdCeCCPCPShAcYgnTlFMrCZEMLzeESg9/X2ItjPm9xiKdELITyPRwR6gLBAX6mjF0J4pBMGeqXUDKVUmlLK6fNelVKJSqkcpdQG8/WszbzxSqmdSqlkpdTjrsx4fYVLoBdCeKi6lOg/AcafYJmlWuu+5msKgFLKG/gfcD7QHZiolOrekMw2RFigrzTGCiE80gkDvdZ6CXD8JLY9CEjWWu/VWpcCXwGXnMR2XCIsQEr0QgjP5Ko6+qFKqY1Kqd+UUj3MtNbAQZtlDplpTimlJimlkpRSSY3xQOaIIAn0QgjP5IpAvw5op7XuA7wN/HgyG9FaT9NaJ2itE2JjY12QLXuWh4TLwGZCCE/T4ECvtc7VWueb7+cAvkqpGCAVaGOzaJyZ1iSigv0oKa+ksLSiqbIghBBNosGBXinVQimlzPeDzG1mAmuATkqp9kopP+Ba4OeG7u9kRQX5AXBcxrsRQngYnxMtoJSaCSQCMUqpQ8BzgC+A1vp94EpgslKqHCgCrtVG/Ui5UuoeYC7gDczQWm9tlKOog6jgqkBveWC4EEJ4ghMGeq31xBPMfwd4p4Z5c4A5J5c114q0BPpCKdELITyLx9wZG20J9PkS6IUQnsVjAn1ksNTRCyE8k8cE+rAAH8IDfdmbUdDUWRFCiFPKYwK9UoouLULZdSyvqbMihBCnlMcEeoCuLULZdTRPbpoSQngUjwr0nZqFkFdSzrHckqbOihBCnDIeFehbRwYCcDinqIlzIoQQp45HBfqW4UagP5Jd3MQ5EUKIU8ejAn0rS6CXEr0QwoN4VKAPC/QhyM+bw1KiF0J4EI8K9EopWoYHSIleCOFRPCrQA0SH+JMl490IITyIxwX6iEBfsgvlSVNCCM/heYFeHikohPAwHhjo/aREL4TwKB4X6MMDfSkqq6C4TB4pKITwDB4X6COCfAHIleobIYSH8LxAH2iMS58tgV4I4SFOGOiVUjOUUmlKqS01zL9eKbVJKbVZKbVcKdXHZt5+M32DUirJlRk/WZYSvdTTCyE8RV1K9J8A42uZvw8YobXuBfwLmFZt/kitdV+tdcLJZdG1wgMtgV760gshPENdHg6+RCkVX8v85TaTK4E4F+Sr0VhL9FJ1I4TwEK6uo78N+M1mWgPzlFJrlVKTaltRKTVJKZWklEpKT093cbaqRAQZdfQ5UnUjhPAQJyzR15VSaiRGoB9ukzxca52qlGoGzFdK7dBaL3G2vtZ6Gma1T0JCQqM9AirYzxsfL0V2kVTdCCE8g0tK9Eqp3sCHwCVa60xLutY61fybBswCBrlifw2hlCIiyJcsKdELITxEgwO9Uqot8APwN631Lpv0YKVUqOU9MBZw2nPnVAsP9JWqGyGExzhh1Y1SaiaQCMQopQ4BzwG+AFrr94FngWjgXaUUQLnZw6Y5MMtM8wH+T2v9eyMcQ71FBPlJ1Y0QwmPUpdfNxBPMvx243Un6XqCP4xpNLyLQl6O58vARIYRn8Lg7YwHCg2SoYiGE5/DIQB8R6CdDFQshPIZnBvogX/JLyimrqGzqrAghRKPz2EAPSKleCOERPDLQV413I4FeCOH+PDLQW4dBkC6WQggP4JmBXkr0QggP4pmBXsakF0J4EM8M9OZTprJkTHohhAfwyEAfGuCDt5fihTnbKSgpb+rsCCFEo/LIQO/lpbiyfxxaw6GsoqbOjhBCNCqPDPQAF/RuCUBesdTTCyHcm8cG+tAAYzy3vGKpuhFCuDePDfRhZqDPlRK9EMLNeWygDw0wuljmSoleCOHmPDjQW6pupEQvhHBvHhvoA32Nh4RLHb0Qwt3VKdArpWYopdKUUk6f+aoMbymlkpVSm5RS/W3m3aSU2m2+bnJVxhtKKUVogI+U6IUQbq+uJfpPgPG1zD8f6GS+JgHvASilojCeMTsYGAQ8p5SKPNnMulpogK+U6IUQbq9OgV5rvQQ4XssilwCfacNKIEIp1RIYB8zXWh/XWmcB86n9hHFKGSV6CfRCCPfmqjr61sBBm+lDZlpN6Q6UUpOUUklKqaT09HQXZat24YG+ZMt4N0IIN3faNMZqradprRO01gmxsbGnZJ+RwX5kyQiWQgg356pAnwq0sZmOM9NqSj8tRAf7cbxASvRCCPfmqkD/M3Cj2ftmCJCjtT4CzAXGKqUizUbYsWbaaSEyyI+cojLK5SHhQgg35lOXhZRSM4FEIEYpdQijJ40vgNb6fWAOcAGQDBQCt5jzjiul/gWsMTc1RWtdW6PuKRUVbBmXvozYUP8mzo0QQjSOOgV6rfXEE8zXwN01zJsBzKh/1hpfVaAvlUAvhHBbp01jbFOwBHqppxdCuDMJ9EigF0K4Nwn0SKAXQrg3jw70EUHGUMVZEuiFEG7MowO9v483of4+ZEqgF0K4MY8O9GC5O1YCvRDCfXl8oI+Su2OFEG5OAr0EeiGEm/P4QO/v48XWw7ks3X1qRswUQohTzeMD/VmxIQBMW7K3iXMihBCNw+MD/d0jO3JWbDDpeSVNnRUhhGgUHh/oA/28GdW1GfsyCqis1E2dHSGEcDmPD/RgVN+UlFeSml3U1FkRQgiXk0APtAgPACBNqm+EEG6oTsMUu7vwQGMohNyiEzxWMPcI7PoNdLUqHi9v6H4pBEbYp1eUwd4/odLJdlv2hbCWJ5tlIZpWeSnsXwKVFaC87F9e3jbTlvcKYjqDf0jj5ak4B47vc0z3C4GYjo233zOABHqqAn3OiQL9stdh9QfO5x3dAuNesE9b8Q4smFLz9pS3Y1q3i2Dw3x3TozpAaIva83e6yzsGZYWO6aEtwTfg1OfHVfYtgS+vhgon92Oc+wiMfPLU56kmZUVweL1jurc/tO5vBOS62PAlzH6gfvvudjFc80X91nFm+TtwaI1j+oG/oKCGbtK3zoW2QxzTy51cxSsv8PZtWB5PMxLoqUegzz4Asd3gxp/s0+c+CWumG6/q2p8LY6oF+7Ji2L/U8UtWkAbrPoNt1bYPEN0J7llT9x9ifRXnwMHVjum+QdB2KHhVq+U7tBaWvALoupXoirNhx2zn+44/B276xf7YtIbUtVCU5bh8ZDzEdHJM/+YmI+hWFxwDt82DwMgaDr6Bds0FNAx/0D5935+w8j3j+OuqzSA4a5Rjetp2yDlkn6Y1bPkOjm1zXD44xjjB+AXbp89+EA6ucr7vKz6CXlfWLZ/7/oSw1nDN50Y+KitAV4K2/K0007SRtuIdOLzRcTsV5fDrg5B31HFei14w8mn7717eMZj/DAQ3g4Bw++VjOsMFrxgnLSsNP9wJcx6FVv3sl0/fCQdXOjk4ZRxXt4vtkwuPQ9IMqCx3XKX7JdCsm2N6yiooyXVMj+0CEW2d7LtxSKAHwuoa6HMOQWQ7CG1unz7uBeNLqSuqraCg5+VGYKqu3VDn+xg0CQoz7dP2LIS/3oTtPxulX1vhcRDWynE7i19yHvT8wyB+GHhV+9cnfQwZO53nqdfVRmnP1vovjRNfVHuorKz6cTv9oZvTCbdC3CD77Rxeb1wl/bu5faCvrHBe5QXgHw4P7wC/oKq0ggzY9iO0G27/gysrNEqfG/7P+DHa8guuX/CvKIejG4282dq3xAgi5z1jn556Acw4Hxa/WPd9+IfBQ9vA1yZA5x+FD0ZAhbPSpzd0GuN4dbh/KXw0xvk+Rj0NcQPt02ZNhpXvOpaIs1Ng9zzHY85NhR6XQ+sBdTuuIxuNz6m0wP7kk7rWKNzEdLZPrygz9rv8Hcfvha40ClvNutZt38PugzUfmSdkGz5+MPQeCIqyT1/xLmz53jHQ//Um/PWG833sXwY3VyvI7FsCn17sfPmItnDvevA+NSG4rs+MHQ+8CXgDH2qtX6o2/3VgpDkZBDTTWkeY8yqAzea8FK31BBfk26V8vb0I9vOuW6B3dvkX2gKGP+CazLTo5ZgW3QmWvw3f3Og4zycAOoy0/zFUlELyH9C8l2O7weH1RjuDw3YC4dL3jB+crfVfwNqPYfM3jutc/BYMuOmEh1SrXlcaJ87iHMd5ke2heU/7Y0vbBj/fCz/cASE2J9zcw8bf0c9DG5sgpjWkrDCuuuZWq0Lx9jOOufpnnr7TKLFWb4s5uhkOObnqARj+kGNa6wHw9DHnyzuTshI+Hg8vxjnOU95w/feO/8+QZs5LhlkH4MgGx/SgGGh3tuOVYb/rjSu01LWO67Qb7liYUINhyOTajsae5Xu18j37bSUvAJRRtWIbcLU2vnuZux23FRlf9yAPMOIfxquuMvfCxpkwtdpvofA4dB4PE7+yT//zZaNg9cEI+/S8IxAYBdd9bX9Vl7oOfnsUXu3sWOAKioG7ltc9r3V0wkCvlPIG/geMAQ4Ba5RSP2utrdeLWusHbZa/F7C9RirSWvd1WY4bSXigb1Wgr6w0qlFslRUZ1Q9hrU953ghvDZP+dMyT1kZpKMtJA1SPy+Gy98Gn2rNwKyucX0p6+9uXkC3iEmDMP41SlC3lDQFh9TsOZ7x94ZyH6758q/6w8SsjKFbXOsHx8lwpuOZLSE1yXP6vt+D725zvxyfQsdrD2xfG/Auad6+2Dy9oM9j5dupT1dZ2iHHydFaN0awbdBpd921FtjNedTXyKaN0S7WTm6v+z636Gp/Twn85zmsz2LFUrRT0/1vD93syht1v/G6qX6ErLxh4u+P/dMDNRgGkrNg+PaS5cUXfptpVbKt+UJgB+U4KAf6hDc6+M0pXL7VUX0CpocDzWutx5vQTAFprp9ejSqnlwHNa6/nmdL7Wul5N7QkJCTopyckP09U2fWtUhwBLkzMI8vNmQNtIo+TmLHhC/eoxxemtIMMouVfn7Q8dR5/ZDcSno4JMKM1zTA9pDr6Bpz4/bkYptVZrneBsXl2qbloDB22mDwFOiy9KqXZAe2ChTXKAUioJKAde0lr/WMO6k4BJAG3bnqJGitUfGA1ZEW2J14XoEiAjwyhdJNzieHb1CYCuF52avInGFxwDPa9o6lx4juBo4yVOOVe3BFwLfKe13TVPO611qlKqA7BQKbVZa72n+opa62nANDBK9C7Ol3NlxdBhBEycyZTPkjh4vJDf7z73lOxaCCFOlbr0+0oF2thMx5lpzlwLzLRN0Fqnmn/3Aouxr79vWuVFRikdCPX3oaDUSbcpIYQ4w9Ul0K8BOiml2iul/DCC+c/VF1JKdQUigRU2aZFKKX/zfQwwDHDS6beJlBUZ/cSBkAAf8osl0Ash3M8Jq2601uVKqXuAuRjdK2dorbcqpaYASVprS9C/FvhK27fudgM+UEpVYpxUXrLtrdPkyoqsDW4h/j7kl5SjtUY11k1JQgjRBOpUR6+1ngPMqZb2bLXp552stxxw0jH8NFFebK26CQnwoaxCU1JeSYCvk6EJhBDiDOW5o1dqbZbojW5dof7GOS+/RKpvhBDuxXMDfUUpoO1K9IDU0wsh3I7nBvoy8yEjZok+xN8Y70ZK9EIId+O5gb7cvF3Zp6oxFiBPSvRCCDfjuYHeMi662b0yNEDq6IUQ7smDA71Zoje7VwabJfrM/BIq5CHhQgg34rmBvtyso/cx6uijQ/wAePyHzdz95bqmypUQQric5wb6aiX6sABf/HyMj+P3rU6GiRVCiDOU5wb6aiV6gLIKY8z1iCD3el6kEMKzeW6gr1aiB3jqAuMRdO2ig52tIYQQZyTPeGbsqmmOD5iwPHrOt+qpSref04GVe49zKKvwFGZOCCEal2cE+pX/g8Is40HattqPcEgL8feW4YqFEG7FMwJ9ZQV0uwguffeEiwb7+1BYUnHC5YQQ4kzhGXX0lRX2T2GvhWW4YiGEcBceEujLwatuFy/B/j6UlFdSbvbAEUKIM51nBHpdAV51G2PecodsRn4pq/ZmNmauhBDilPCQOvpyUHUM9H7GckNeXADApufHEhYg/eqFEGeuOpXolVLjlVI7lVLJSqnHncy/WSmVrpTaYL5ut5l3k1Jqt/m6yZWZr7PKynpV3djKKSxrjBwJIcQpc8Lop5TyBv4HjAEOAWuUUj87efbr11rre6qtGwU8ByQAGlhrrpvlktzXVWU5eNWtlsqr2vNic4rKaNMYeRJCiFOkLtFvEJCstd6rtS4FvgIuqeP2xwHztdbHzeA+Hxh/clltAF1R5xJ9YpdY7juvEx/dlABAbrGU6IUQZ7a6BPrWwEGb6UNmWnVXKKU2KaW+U0pZCsF1XbdxVVbUvY7e34eHxnSmZbgxBk5ukXS1FEKc2VzV6+YXIF5r3Ruj1P5pfTeglJqklEpSSiWlp6e7KFsYDwGvR4neIizQWF5K9EKIM11dAn0q2FVTx5lpVlrrTK11iTn5ITCgruvabGOa1jpBa50QGxtbl7zXjTb7w9exe6VFWKDR0ya3SAK9EOLMVpdAvwbopJRqr5TyA64FfrZdQCnV0mZyArDdfD8XGKuUilRKRQJjzbRTp9KseqlnoA/x80EpyJVnyAohznAnrM/QWpcrpe7BCNDewAyt9Val1BQgSWv9M3CfUmoCUA4cB2421z2ulPoXxskCYIrW+ngjHEfNKs1xa+pYR2/h5aUI9fcht6iMikqNlwJVrUeOEEKcCepUca21ngPMqZb2rM37J4Analh3BjCjAXlsGGuJvv73hoUF+pJTVMZZT85h0rkdeNIcr14IIc4k7j8EgjZL9PWsugGIDvZjb0YBAB8t2+fKXAkhxCnj/oH+JKtuAFpHBrIlNQcAX2+pthFCnJk8J9CfRIk+LjKIikoNQHFZJfd/td6VORNCiFPCAwL9yfW6AWgdEWg3/dOGw67IkRBCnFLuH+itdfT1b4yNiww88UJCCHGac/9AbynRn0QdfYfYEBdnRgghTj0PCPSWO2PrX6JvFxXk4swIIcSp5/6B3lp1U/9D9fKSnjZCiDOf+wf6BtwwBViHK7Yok2fJCiHOMB4Q6E++Hz3Aed2aM7RDtHW6oETGvhFCnFk8INA3rEQPUF5ZVYrPk0HOhBBnGPcP9Cc5TLGtNpFVjbIFpRLohRBnFvcP9A24YcriX5f2ZOKgtgCMf2MpS3e78MEoQgjRyDwg0Desjh6Mxwte0b/qCYhzNh9h/rZj3Dfz5IdEmDp3J7d/uubECwohRAN5QKBveIkeIDrE3/o+LbeEOz5L4ueNhyktN6qG9mUUkJ5XUtPqDt5ZlMwf29NOKi+Z+SXW3j9lFZWs2X9qh/gXQpxZ3D/QN2AIBFvtY4JZ+o+RjOgcS3J6vjXd0gtn5NTFnPvfRQ3aB8DxglI2H8qpcX5ZRSUD/v0HT83aDMAbf+ziqvdXsPFgdoP3fSbZn1HAfnMIaSFE7dw/0Lug6saiTVQQzUL9OZBZaE2b9HmS9QHiRWUVDd7H2wt3c/2HK2ucn1VQCsC3aw8BsOuYcdI5klPU4H2fSRKnLiZx6uKmzoYQZwTPCfQNrLqxiA31t5tesz+L/y1MPuntaa3tppPT8sktLqfcyY1ZZRWVpJnVQ5bVLOPkl1Zoh+WFEALq+ChBpdR44E2MZ8Z+qLV+qdr8h4DbMZ4Zmw7cqrU+YM6rADabi6ZorSe4KO9104AnTDnTrFqgB/hgyd56bcM2uJeUVxLgW5W3/ZlGdURBSQXhQfbn4a7P/E71URl8vY1lLG0Fp6vU7CJC/H0ID/Rt6qwI4XFOWKJXSnkD/wPOB7oDE5VS3astth5I0Fr3Br4D/mszr0hr3dd8ndogDy65YcpW87CAWuePeGURP21IrXH+wh3HrKVygGKb6p7S8kpSs4wqmLySMrv1CkrKqajUlFUruVsCfV6x/fJ1UVGpeW/xHtJyi+u9bn0Ne2khY177s0HbOJBZQPzjv7Jo58k1YgtH5RWVHDxeeOIFT0Nztx5lwL/m2/2GzkT5JeVUVjbuFXldqm4GAcla671a61LgK+AS2wW01ou01pZvy0ogzrXZbAAX1tGD8dSp2hzILOT+rzY4nZeclsetnyTZPanKtl7/YFYhlv/3j+tT+TbpoHXetiO5DtvTWuNjFvGzC41A/9q8nTz0jfP9Vzd/2zFe/n0HbyzYXaflGyqtHr2SnNl22PgMPlu+3wW5OTMcySmi89O/WR9p6WpT5+3inP8uqlMbT25xGX9sO9Yo+TgZ//51G5kFpRzNafyCSmMpLqug53Nzefn3HY26n7oE+tbAQZvpQ2ZaTW4DfrOZDlBKJSmlViqlLq1pJaXUJHO5pPR0F96QVOmaXjcWzh5GcmHvlk6XfWvBbjbY9IZJTjOqZdanVKUVlRr5yy4s5Y0/qgLu1Hm7ePS7Taw9kAXg9Ieenl9CiVllk1NkBPq1KVn8vuWo0xLCe4v3sPVw1XYsN36F+tf+2Tzz45YGlaKdtTcA5BSW8eWqAw7tFCdyNLfqhLEvo4ARryzi8e83nXT+TmcLtqdRWl7J5ysONMr2/0rOAKhT1+D7Zq7n9s+STpuGfz/zara4/Mwt0WeanSu+Tjp4giUbxqWNsUqpG4AE4BWb5HZa6wTgOuANpdRZztbVWk/TWidorRNiY2Ndl6kGDFPsTESQYx3zOxP78dmtg+zSdh3L47X5u7jn/9axYPsxissq2Hk0D8AanKGqRH/hW8v4ZaPjowp/23wEMAJadYNeWMCPZjWRJdDnF5dTWFpBis3l+PI9Gaw9cJyXf9/BJe/8ZU1PTsu3y4MzZRWVfL7yALd8bH9zl9ba+jxdW9sO5/K3j1ZRUFJOTmEZr8/fxXHzywxGcLd44Ov1PDVrC8lp+Vw7bQVfr0lxun+LbPMYUzKrPosF249xILPQ4Yfyv0XJfNPIP576KCgpr7WK4f6v1vOd2ZPKluUz9m6kh9NbhuKuy6isu8zvb3FZ07cH7c8oYE+68T3IKSzjWG4xr8/fxYaD2Xz8174mzp3h9y1HWLKr9kLr8Xzjt+GtGndI9LpEv1Sgjc10nJlmRyk1GngKmKC1thYPtNap5t+9wGKgXwPyW38urqNXTv4hSilaVXu+7OxNRoA+lFXEbZ8m8fLvO9h5zLH6pai0guXJGaRmOy8lrdyXCcD+TOf1qJbC8I8bUrnjsyQ2mn3wbat6rpu+iiveWwFAuU1wtlT37M8spLisgk2Hsnnw6w12Adw2SINxs1ZxWQXv/7mXs56cY70isZi5OoWluzO4+//WMXNNCm8u2M3crUet8w8crwrSm82rlIz8UlbuPc5j32+229bnK/bT6/m5/Lb5CMlpeXy5yijVFtjs89+/bgcgyNeb4rIK6xXLK3N38o/v7Ev5HZ+cwytzqy6Ri8sqGPbSQua7oDri6zUpfLOm5hNLj+fmcun//nI6r7isgp82HOaRbzc6zLOchCsqNAu2u77axFL1V5fB+irML1vK8UK223y/th/JtXb7rav9GQVOT2w1OZpTTKHNOFO2XWvnbTvG4P8s4M0Fu7n0f3/xz1+2NWrnhNLySrILT3y8f/9iHTfOWF3j/JzCMg6bV0fejfzsi7oE+jVAJ6VUe6WUH3At8LPtAkqpfsAHGEE+zSY9Uinlb76PAYYB21yV+TpxcR09wE1D23Hd4LZ2aW2rPY2q+o9yfUo2O47kOWxr6rydXPfhKqf7CfD1YuvhXFbsyeSATSm2e8swh2W1xi5gWX6ItX3hs8wv65Jd6Vz/4Sru/2oDs9anWnv+AGTkV13SV1RqBvz7D274cBWfLDdKTd2e/d16ktJa84d53It3pvPSb0ZQXbI7w7qNwzYntAyzNGMbNOZuPUphqdHw/M6iZIrLKpn85TpGv7aELamOJ0qL0opKLnnnLy58axnrUrKs6e8s3M2W1BwKSsopr9T8b9Ee67wdR/NIzS7in79srXG7dfXY95v5x/ebnFaZWa6cdhx1/P8D7E2v+cYvS5XK10kHue3TJP41e1u9Gh+11hzOLmLV3kyn63nXJ9Cbx3bTjNWc/+ZSps7dSVlFJee/uZSJ06vu/Sguq6DvlHn8vPEwmfn2VUJrD2TR67m5JE5dzCPfbqxzQB7y4gLGvbGEoznFJL5if2PiR8scS/DVC04VlbpO1VM1VTPa+vsXa+k7Zf4JlzuRPlPmcefna4HTINBrrcuBe4C5wHbgG631VqXUFKWUpRfNK0AI8K1SaoNSynIi6AYkKaU2AouAl7TWpzjQu7ZED/DPS3ryn8t6AdA8zOhu6edj/1FuPWwflPZnFrA/s4BB8VEAxEcbJ4aVe6uGL3j8/K68dnUf6/SQDtFoDROnr+RAZiHDOhrj4t85ooPdtsd0b+6Qx+1HcskpLON5J0FMa01aXrFd4+jaA1kE+xsnwzSbOnBLMAasATTpQBbHbJZ54ofNXPbuX6xLyeaIk4Yx28tXy3zbennbq487P1/Ly7/tYG96vt0+TqSsQrPzmBFIbdtAps7bxa2frHH44X+TdJBPzEv8QF/XFQKqN5pnFZQyupbeRrPWH+I/c7Zbpy979y9W76v6TlQPTh8t28d/f99JZaXmtfm7WLY7w+5kbFlmt/lZfLRsH2e/tJBrpq3k9T92OezfUmWQ66TX1sq9mfy+5Yh1urzaSeydRcnM3mRUN+44mmctjKRmF5FdWMZ9M9cz4N9/sGhHVfvOltQc8mye6ZBZYJ/3nKIy5m87Zvf9sJxgDh4vYsiLC2q8urVlW1gBePanLQx84Q+HK1BbC7Yfo+NTv5Gc5vyEbLHQPB7b6q7yikrunbne6R3qf+5Kt7ZrpOUVU1Ra4XClfDS3mLGv/2ktFLhanaKf1noOMKda2rM270fXsN5yoFdDMthgLhimuCYLHx5BZJCfQ3qwnzcFpRV0ahbCgcxCSisqrdUkNw+L55WrepORX2KtTrG44xwjgD/0jXEJPzA+isU7q4Lk9YPb8e51AwgP8rXr2RPq78PbE/txr80ga39sT6PPlHlO8/3QNxuZtd6xC6ilxLz2wHGGnmWcVGxLZN/WUOdtCeTv/7kHpeDRcV347+87rfNt2ySO5BQbvYJsYsa2aifFT1cc4FOz8TEuMpBDWfZBOjTAp9YSaPXtFZdVWLutBvp6U1mp7ap1LIEku7CUsADfBj1CctW+4/RsHW6drqkUb/Hg1/bVNetTspmz+QgZ+SUs35PBASddH/dl5LPtSC5vmb2lgvy8eXRcF0Z3a05YoC//mr2N6GA/1j4zhvf/rLqCOZDhuC0fs+7/qVlb6Nw8lIFmQQTg2mlGKX14xxgSu8RS4eSmvM2Hqj7rEa8sZv9LFzr0glmyO53ELka7W/WTUnpeCS3Dq6o9Zyzbx5sLduPtpWgVEcDwjrEM6RBFfaVUOxl8uSrFur+20fZX35YCzM9mG9ma/VlsP5LH5ysO8M51/Whmdqmev+2YXdVfblGZdQysA8cL+WXjYZYnZ7D2mTF2V0+3frKG8T1a8NIVvRj0wgIu6t2SKwfYd0zU2rjLfePBbDo2C6n38Z6I64q5pytLiV65/ibgDrH2/5BpfxvAnvQCluxKZ8XeTC7t15q7R3Zk2+FcLnhrKQB92kTQOiIQH++q/FzStxW9Woc7XL6dfVa03fTwTjGEBTg2Bgf5e3Nxn1b8sO4Qi3amc1ZssLWhyhlnQd7W1Hm76B0XwYfL9tmVxr9JMupUh3SIsrsSsZi/7RgJ7SK5K7Ejv2w8wvYjucRHB1lLYAG+XhzJKXZodHbWddQioV2kQ6Af0705P6yr+RhsexYB+Pt6c8gs0YcF+ljrRS0OZhUyf9sx7vgsiYfHdObe8zo53W5xmdHI3bl5KMVlFWxOzWFgfBQlNr0+NlQr0Tkb0vpQViHDX655XKQ96fms3JtZ40li0c50zu9V1dOrsLSCf/6yjY+W7eO96wcARm+OotIKa68O43PwYl1KFl+uTGHl3kwWPZJo1x7zw7pUBsZHobXmnv+rKjQsS85gWXJV9ZutFXsz7aYPHi90uHral1HA3f+3zgiyUcF289LzSpixbB8X9m5J87AA65VFRaXm4PEiZq5OYeZqx0b6E9lxNJfKSk1phf0Nien5joH+8neXA1W956Yv3WutTluXks34ni0AuOOzJLv1DhwvZNjLC5n2twRrucXSYSC3qOoKqaJSM3/7Mbr8FQoY7XehAc5D77G8xukq6kFDIDT+OW1sjxZMTjyLC8wvTJj5z+zSwvgHd24eQmuz0da2uuDagW25/Zyq6phZd53NrLvOpm+bCGvazWfH2wV5S9URQKiZbjl53DKsPd9PHsqSR0ey+snzWPxIIjU16l/erzW948K5+ex4u/TNqTnWIO/n40UfMy8D2kVy98iOAPSOC6e60WY1kuUO4qsSqtrxuzQPZW967ZemfWyOOS4ykBibUUNHd2vGlEt68J/LejHp3KrP685z7auyLAHy1/uGM7pbM9LzSvjRPLkdyy3huulGm8i3fx/Kq1f1oaxCW3/EH/21z1ptoLVm5uoUa0+hyV+sZezrSzicXcQ/vtvEVe+vYE96vvVqAWB9SpZ1/bcX7ObdxVUlajDaTLY7aauxtfNonrX9pCbVG5rBaPh/8beqaqDktHy0hg4xRnA9kl3M5e8u5/t1h0jNLiLleCGFNlUZ+SXlvPjbduZuPcavm484bN+Z7dVO0sv3ZHAk2z5YbTucy5zNR1mzP4vv19k3wK7Zn8WU2duY9FkSBzILmLf1GO1j7E8Gzjx/cfV7Nu39uTOdNxbspuszv9udeKq3GdgqNj8L2zYTS5VLTpFj1dbinekUl1Uydd5O6/e6olKTmV/C+W8utVu2tLyS1+ZXVZ3NXG1cHQf72dc0pNWjurI+3CvQr5oGK961f+1fZsxrhKqbmlw/qC1vT+zH1QONIOftpVj6j5H8cNcw6zIhNn3Xq5cw+rWNpF/bSJRSfHHbYBY+PILnJ/SwW+a6wW2tJX7LWPmWcW+C/b0Z0C6KttFBNAsLID4mmPXPjGH+g+c65PWiPi35+Z7hDmP4vDK3quqlfXQwz13cnd5x4Tw2viu94yIA4+Rz36iOdg3RF/dpBVS1XVzevzXXDmzDLcPi6dgs1KHtwtIXOsTfh64tQnlkbGfrvEWPJBJmDplw57kd+PCmgdw4NJ4AX29uHdYegFev6mN3H4PlRBoT4kePVuH8Y3xXAny9rPcjANaupx1jQ+jRuqph+75RHckuLGOv2ZV1w8FsnvhhM/d+tZ603GIWmdVoX6w8YL3Mn75kL6NeNergh3eM4VBWESv3HmfSZ0m8On8XoQE+/PeK3txvXiXMXJ1i17Bu0S46iOsGt+W+8zqRlldi1z7RwSbwPX1hN4d1bS3fU1XC/mCJcZKZduMALuvX2q6RGow7jW17svyy8TAf/LnXOjLquB5VbT+Tqp1MbY3v0YJZd52Nn48X24/ksWhnGlHBfsx/8FzuGdnR4Ua5MJvSrGWI7Y2HchjxymJSs4ucDjNSXYvwmu9QvyvxLA7nFFurtt63Odla2py01iSn5ds1vi6waUvo3DyEAF8vDmcXUVmp7U7mFjvMk9ymQzn885eqpsdbP02yu5IKC/DhrFjHk1efNhFsnTKe967vDxjf2bRGKtG7V9XNH89BmZOGmpDm4H3iL4+reHkpa8CzaFOtV46fjxez7x3OpkM5tKrlSzu8U0yN8165qg/7Mwro2My4YvCp5V6BiCA/IoL8uCahjV2fc0uQjgkx2hp6x4WzqdowyVHBfvRvG8nP9wy3pu1/6ULr+4fGduGZH7cQ6OdtDbTDOsZwJKeYFmEBvHRFb8Do217dmB7N+XXTEcb1aMGrV/exayzz9faqqs6qdkXSIjyAvf+5AC8vZXePQUyoP6nZRdZqtc7NQ3njmn78/Yu1KFXVHTUyyJfIYD9CbILO2B4teGthMjuO5HFWbIj15LBkV7q1Z5Sft5ddKf0rmy6VN50dz8aD2Tw5a7M1T69d3Zcx3ZtbTwzP/VzVON4iLIDXru7DdR+uIjrYj/9c1ovFTm5MG9Q+ir0ZBTQL9ef2czoQ5OfDk7M2OyxX3exNR/Dz9qJddDAdYoIdGlNv+zTJ6XqZBaVc0T+OV6/uQ/9/zed4QSlXDYhjms2YTlcOiLN2j+zeKox+bSNpHx3MJ+Zdy38fcRadmodaT/i2RndrzqhuzXjo6412J2CL4vJKfrjrbGuVSnVBft6E+Nc8ZtJdIzvy1ZqD1gbPr23+R5Y2gncX7+GVuTuJDnZsYwNoFhpAeaVm+tJ9fPzXfh4e28VhmXnVuuV2bBZCVJAfq6s9HyI8yJdHxnZh8pfraBkeYO2QcE5H47d9fq+W7HvxAq6bvqrRSvTuFegf2u483TcIvE+/Q+3ZOtyu4a6+WkcEWgMrVPWJLq9lJMuXr+xtDfTrnxlDpPlFt1SRlJZXWhtA379hAH//Yi1dW4aeMC//urSn3fQlfVtzSV/7G6idlWrG9WjBr5uO0DrCONkFmpeyl/ezX1dVj/RU3ezTIiyAYD9vXrislzWg2u5rXI/m/N8dg1m4PY0Pza54weYVla+3FxMHtaVtVBAdm4Xg7aVYtDONNfuP241ZZOkNcdfIs3jjj91EB/txYe+WfGZzx2qzUH+uGBBnDXZgBGkAPyc3PK188jzyisvoEBPMkxcYJfWuLaquMBK7xLJ4ZzoD2kXy1ZqD1mqWwSdonPz5nmHM33aMIR2iqajU+Hp7cevw9pRWVNKpeSgPfb3BLuhf3r8187YeI9+mN8yors0A+OzWQfy88TAdm4Ww+fmx9HreaOD/7xW9rYG+V7Xv8ENjOnOfeQUTG1pViGkRFsDR3GJahAdwUe9W/LAu1dqDxVZeURn920Zy9lnRdlcoFoG+3tYTdKvwAP6eeBZju7dgwjvLCPD1JsTfh6sS4vjgT+PEZNTTe+Hr5UVGfgl70vN5w+yBZFvy/u+VvVmfks3M1SnEhPihlFGNU16p6zREwaiuRjUh++3TQ/19Ob9XSxY8PILoYD+zTaKV3XdUKUXzMH/Wpjie+Fzh9It+DREY0dQ5aFIjusTyw/pUa5tATX69bzjrDmRZgzxUPUGrtKKSr+8cSnpeCX3iwnn5il5M6FPbiBd1V73xGuDi3i0pr6jkApvGxX0vXmB9bzl5OQuUFoF+3mydMh4wevUs3JFG/7aR1vlKKc4+K4ZfNlbVO9s20L14eVV7x1mxwdYA5u/jxYOjO1u7JfZvG8FVCW1YtjuDKZf0ZKXZEBkT4oevtxcdYoO5YUhba6Cf+8C51tE6B7SLonvLMP57ZW8uenuZdX+hAb4sfCTROm1bAn7v+gGsT8mitTnshuXB9B1igokJ8XfowfLA6E7ERwfTOy7CWr1mEezvYy2VTujTilfn7WR9SjbLkjNIzSriqoQ4Pv5rP4PaR7Evo8DaAGlbGAm1aSOy7Zl0ttntt2PzEHYey+OagVXtMpbjaRMVSIi/L0dzi7m8v9HjZHzPFizckUbXFqHWdpWRXWKtJ4nqI2PMvGMIE6evtAZzMP63Nw6NB+Cvx0dZlx3bvYU10BufmfHd+2zFAT5bcQAvBZ/cMpCbzTu+f7lnOL3MNqeZq1PILymnY7MQlu7OwM/Hy9rff1TXZk5PTkM7RHPfeZ14xxyyvFV4AEH+PiSn5RMWaOT1LPP7/5CTqwOAQe2jHbppu4p7BXoPd0nf1pzTKZaoGi5HLXq0CqdHK/tSWIQZkErLK+2uFK4Z2NZh/ZNlBKFwbj+nA2EBPmw7kotSyvrDt7C9+/iGIe1IOV7I7bXUEduanHgWtw1v7/QHY9uWkNjZ+TAb53aKZdexfEZ3a870G40eLB8u3cuFvVvywmW98PZSfDf5bAAig335cOlePrxpIN1bGSXx0ABfvJRRNWd7wo0N9WfO/ecA8PIVvaxXFNUppZh6VR9ahQcQ6OfN2R1jrF31vMzPRSnFlQPi7LpOAjwwurPD9mry8NguZOSXkPDvP2geFsDTF3bn0XFd8PX2olLrGm/guW9UR8LNLsWW9gJ/H+Ok+eLlvZh0Tge7EV4tXRO7tgjj8fO7sv1IrrX74BX944gJ8WNYxxi6PP07AB/fUjWUSOfmIazYm0nriEBSs4usJ81AP2+CzCu/Spuzga9NT7YB7SL56e5hfLUmhZmrD3JWsxDaRwex7UguXVuEMvWqPvRsHc6ap0Yzc3WK9f9nuRkxIsiPczvF8vFf+2ke5s8jY7uw7XAuj4zrwoo9mdw4YzX92kaw+1g++SXlvHt9f0L8fawntn7tIrmoV0smf7nOaU85Z64b3NbhRkyX0Vqfdq8BAwZocWoVlZbrdo/N1l+uPNDUWWk0ZeUVeuWeDL01NUeXlVc4XSY5LU/HPz5bL0/OsKZVVlbqysrKOu8nq6BEp+cVNzi/tt6Yv0uvT8myS+v01Bzd7rHZ1tfJ2JCSpXOKSl2QQ+dKyip0t2d+0+8s3F3rcn9sO6o3Hcy2SysqLdcLdxzTZeUVOq+4TOcVl+kOT/yqf99yROcXl+l2j83WL/y6rdbtvrNwt2732Gz9xvxd+mhOkb5pxip9IKOg1nV+3XRYZxeW6oKSMt3xyV/1d0kHHZY5lluki0rL9fqULP3Cr9us34+Plu7V7R6brR//fpM+nF2o2z02W6/am1nr/lwFSNI1xFSl6zly4KmQkJCgk5KcNxQJIQydn/6N0vJKpv1tAF5KWbu2nm4OHi8kNtTfrrrMFXIKywgJ8Kl1+IDv1h7ikW838s51/biod6sal3OV5LQ8Rr+2hB/vHmbXPfpUUEqt1cYAkg6k6kaIM1RYgC8Z+SUM6xhTY1XQ6aB6jzNXCXcykmx1fdtE0C46iAHtIk+4rCt0bBZq1yPtdHH6fjuEELX6atJg5m9LO62DfFPr2CyEPx8d2dTZaHLyDRHiDNWxWaj1HgohauNed8YKIYRwIIFeCCHcnAR6IYRwcxLohRDCzUmgF0IINyeBXggh3JwEeiGEcHMS6IUQws2dlmPdKKXSgQMnXNC5GMD5Ay7dlxyzZ5Bj9gwne8zttNZOh2U9LQN9Qyilkmoa2MddyTF7Bjlmz9AYxyxVN0II4eYk0AshhJtzx0A/rakz0ATkmD2DHLNncPkxu10dvRBCCHvuWKIXQghhQwK9EEK4ObcJ9Eqp8UqpnUqpZKXU402dH1dRSs1QSqUppbbYpEUppeYrpXabfyPNdKWUesv8DDYppfo3Xc5PnlKqjVJqkVJqm1Jqq1LqfjPdbY9bKRWglFqtlNpoHvM/zfT2SqlV5rF9rZTyM9P9zelkc358kx5AAyilvJVS65VSs81ptz5mpdR+pdRmpdQGpVSSmdao3223CPRKKW/gf8D5QHdgolKqe9PmymU+AcZXS3scWKC17gQsMKfBOP5O5msS8N4pyqOrlQMPa627A0OAu83/pzsfdwkwSmvdB+gLjFdKDQFeBl7XWncEsoDbzOVvA7LM9NfN5c5U9wPbbaY94ZhHaq372vSXb9zvttb6jH8BQ4G5NtNPAE80db5ceHzxwBab6Z1AS/N9S2Cn+f4DYKKz5c7kF/ATMMZTjhsIAtYBgzHukPQx063fc2AuMNR872Mup5o67ydxrHFmYBsFzAaUBxzzfiCmWlqjfrfdokQPtAYO2kwfMtPcVXOt9RHz/VGgufne7T4H8/K8H7AKNz9uswpjA5AGzAf2ANla63JzEdvjsh6zOT8HiD6lGXaNN4B/AJXmdDTuf8wamKeUWquUmmSmNep3Wx4OfobTWmullFv2kVVKhQDfAw9orXOVUtZ57njcWusKoK9SKgKYBXRt2hw1LqXURUCa1nqtUiqxibNzKg3XWqcqpZoB85VSO2xnNsZ3211K9KlAG5vpODPNXR1TSrUEMP+mmelu8zkopXwxgvyXWusfzGS3P24ArXU2sAij2iJCKWUpkNkel/WYzfnhQOapzWmDDQMmKKX2A19hVN+8iXsfM1rrVPNvGsYJfRCN/N12l0C/Buhkttb7AdcCPzdxnhrTz8BN5vubMOqwLek3mi31Q4Acm8vBM4Yyiu4fAdu11q/ZzHLb41ZKxZoleZRSgRhtEtsxAv6V5mLVj9nyWVwJLNRmJe6ZQmv9hNY6Tmsdj/GbXai1vh43PmalVLBSKtTyHhgLbKGxv9tN3TDhwgaOC4BdGPWaTzV1flx4XDOBI0AZRv3cbRj1kguA3cAfQJS5rMLofbQH2AwkNHX+T/KYh2PUY24CNpivC9z5uIHewHrzmLcAz5rpHYDVQDLwLeBvpgeY08nm/A5NfQwNPP5EYLa7H7N5bBvN11ZLrGrs77YMgSCEEG7OXapuhBBC1EACvRBCuDkJ9EII4eYk0AshhJuTQC+EEG5OAr0QQrg5CfRCCOHm/h9YplimfP16sAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    for args in [\n",
    "        {'model_type': 'GraphSage', 'dataset': 'cora', 'num_layers': 2, 'heads': 1, 'batch_size': 32, 'hidden_dim': 32, 'dropout': 0.5, 'epochs': 500, 'opt': 'adam', 'opt_scheduler': 'none', 'opt_restart': 0, 'weight_decay': 5e-3, 'lr': 0.01},\n",
    "    ]:\n",
    "        args = objectview(args)\n",
    "        for model in ['GraphSage']:\n",
    "            args.model_type = model\n",
    "\n",
    "            # Match the dimension.\n",
    "            if model == 'GAT':\n",
    "              args.heads = 2\n",
    "            else:\n",
    "              args.heads = 1\n",
    "\n",
    "            if args.dataset == 'cora':\n",
    "                dataset = Planetoid(root='/tmp/cora', name='Cora')\n",
    "            else:\n",
    "                raise NotImplementedError(\"Unknown dataset\") \n",
    "            test_accs, losses, best_model, best_acc, test_loader = train(dataset, args) \n",
    "\n",
    "            print(\"Maximum test set accuracy: {0}\".format(max(test_accs)))\n",
    "            print(\"Minimum loss: {0}\".format(min(losses)))\n",
    "\n",
    "            # Run test for our best model to save the predictions!\n",
    "            test(test_loader, best_model, is_validation=False, save_model_preds=True, model_type=model)\n",
    "            print()\n",
    "\n",
    "            plt.title(dataset.name)\n",
    "            plt.plot(losses, label=\"training loss\" + \" - \" + args.model_type)\n",
    "            plt.plot(test_accs, label=\"test accuracy\" + \" - \" + args.model_type)\n",
    "        plt.legend()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfd9450",
   "metadata": {},
   "source": [
    "## reference\n",
    "\n",
    "cs224w colab 3 https://colab.research.google.com/drive/1bAvutxJhjMyNsbzlLuQybzn_DXM63CuE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449060ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
